{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abclay\\Desktop\\Car-Appraisal-Master\\venv\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"CarvanaClean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model</th>\n",
       "      <th>details</th>\n",
       "      <th>mileage</th>\n",
       "      <th>Bluetooth</th>\n",
       "      <th>Backup Camera</th>\n",
       "      <th>Infotainment</th>\n",
       "      <th>Screen</th>\n",
       "      <th>Navigation</th>\n",
       "      <th>Hands Free Calling</th>\n",
       "      <th>...</th>\n",
       "      <th>4-Cyl</th>\n",
       "      <th>3-Cyl</th>\n",
       "      <th>V6</th>\n",
       "      <th>V8</th>\n",
       "      <th>6-Cyl</th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Altima</td>\n",
       "      <td>2.5 SR</td>\n",
       "      <td>57543</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>37</td>\n",
       "      <td>19990</td>\n",
       "      <td>2016</td>\n",
       "      <td>Nissan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Civic</td>\n",
       "      <td>LX</td>\n",
       "      <td>51210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>16990</td>\n",
       "      <td>2011</td>\n",
       "      <td>Honda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Focus</td>\n",
       "      <td>Titanium</td>\n",
       "      <td>19216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>38</td>\n",
       "      <td>21990</td>\n",
       "      <td>2016</td>\n",
       "      <td>Ford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Passat</td>\n",
       "      <td>1.8T Wolfsburg Edition</td>\n",
       "      <td>54167</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "      <td>17590</td>\n",
       "      <td>2014</td>\n",
       "      <td>Volkswagen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>EcoSport</td>\n",
       "      <td>S</td>\n",
       "      <td>11168</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>23990</td>\n",
       "      <td>2021</td>\n",
       "      <td>Ford</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     model                 details  mileage  Bluetooth  \\\n",
       "0           0    Altima                  2.5 SR    57543          1   \n",
       "1           1     Civic                      LX    51210          0   \n",
       "2           2     Focus                Titanium    19216          1   \n",
       "3           3    Passat  1.8T Wolfsburg Edition    54167          1   \n",
       "4           4  EcoSport                       S    11168          1   \n",
       "\n",
       "   Backup Camera  Infotainment  Screen  Navigation  Hands Free Calling  ...  \\\n",
       "0              1             1       0           0                   1  ...   \n",
       "1              0             1       0           0                   0  ...   \n",
       "2              1             1       0           0                   0  ...   \n",
       "3              0             1       0           0                   1  ...   \n",
       "4              1             1       0           0                   0  ...   \n",
       "\n",
       "   4-Cyl  3-Cyl  V6  V8  6-Cyl  city_mpg  highway_mpg  price  year        make  \n",
       "0      1      0   0   0      0        26           37  19990  2016      Nissan  \n",
       "1      1      0   0   0      0        25           36  16990  2011       Honda  \n",
       "2      1      0   0   0      0        26           38  21990  2016        Ford  \n",
       "3      1      0   0   0      0        24           34  17590  2014  Volkswagen  \n",
       "4      1      0   0   0      0        23           29  23990  2021        Ford  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['Bluetooth', 'Backup Camera', 'Infotainment', 'Screen', 'Navigation', 'Hands Free Calling', 'Heated Seats', 'Power Seat Controls', 'Rear Air Vents', 'Bed Liner', 'Tow Hitch', 'details'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['Bluetooth', 'Backup Camera', 'Infotainment', 'Screen', 'Navigation', 'Hands Free Calling', 'Heated Seats', 'Power Seat Controls', 'Rear Air Vents', 'Bed Liner', 'Tow Hitch', '4-Cyl', '3-Cyl', 'V6', 'V8', '6-Cyl', 'details'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model', 'details', 'mileage', 'Bluetooth', 'Backup Camera',\n",
       "       'Infotainment', 'Screen', 'Navigation', 'Hands Free Calling',\n",
       "       'Heated Seats', 'Power Seat Controls', 'Rear Air Vents', 'Bed Liner',\n",
       "       'Tow Hitch', '4-Cyl', '3-Cyl', 'V6', 'V8', '6-Cyl', 'city_mpg',\n",
       "       'highway_mpg', 'price', 'year', 'make'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7294"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>details</th>\n",
       "      <th>mileage</th>\n",
       "      <th>Bluetooth</th>\n",
       "      <th>Backup Camera</th>\n",
       "      <th>Infotainment</th>\n",
       "      <th>Screen</th>\n",
       "      <th>Navigation</th>\n",
       "      <th>Hands Free Calling</th>\n",
       "      <th>Heated Seats</th>\n",
       "      <th>...</th>\n",
       "      <th>4-Cyl</th>\n",
       "      <th>3-Cyl</th>\n",
       "      <th>V6</th>\n",
       "      <th>V8</th>\n",
       "      <th>6-Cyl</th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Altima</td>\n",
       "      <td>2.5 SR</td>\n",
       "      <td>57543</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>37</td>\n",
       "      <td>19990</td>\n",
       "      <td>2016</td>\n",
       "      <td>Nissan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Civic</td>\n",
       "      <td>LX</td>\n",
       "      <td>51210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>16990</td>\n",
       "      <td>2011</td>\n",
       "      <td>Honda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Focus</td>\n",
       "      <td>Titanium</td>\n",
       "      <td>19216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>38</td>\n",
       "      <td>21990</td>\n",
       "      <td>2016</td>\n",
       "      <td>Ford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Passat</td>\n",
       "      <td>1.8T Wolfsburg Edition</td>\n",
       "      <td>54167</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "      <td>17590</td>\n",
       "      <td>2014</td>\n",
       "      <td>Volkswagen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EcoSport</td>\n",
       "      <td>S</td>\n",
       "      <td>11168</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>23990</td>\n",
       "      <td>2021</td>\n",
       "      <td>Ford</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model                 details  mileage  Bluetooth  Backup Camera  \\\n",
       "0    Altima                  2.5 SR    57543          1              1   \n",
       "1     Civic                      LX    51210          0              0   \n",
       "2     Focus                Titanium    19216          1              1   \n",
       "3    Passat  1.8T Wolfsburg Edition    54167          1              0   \n",
       "4  EcoSport                       S    11168          1              1   \n",
       "\n",
       "   Infotainment  Screen  Navigation  Hands Free Calling  Heated Seats  ...  \\\n",
       "0             1       0           0                   1             0  ...   \n",
       "1             1       0           0                   0             0  ...   \n",
       "2             1       0           0                   0             1  ...   \n",
       "3             1       0           0                   1             1  ...   \n",
       "4             1       0           0                   0             0  ...   \n",
       "\n",
       "   4-Cyl  3-Cyl  V6  V8  6-Cyl  city_mpg  highway_mpg  price  year        make  \n",
       "0      1      0   0   0      0        26           37  19990  2016      Nissan  \n",
       "1      1      0   0   0      0        25           36  16990  2011       Honda  \n",
       "2      1      0   0   0      0        26           38  21990  2016        Ford  \n",
       "3      1      0   0   0      0        24           34  17590  2014  Volkswagen  \n",
       "4      1      0   0   0      0        23           29  23990  2021        Ford  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1312"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_dummies.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dummies.drop('price', axis=1).to_numpy()\n",
    "y = df_dummies['price'].to_numpy()\n",
    "X = StandardScaler().fit_transform(X)\n",
    "pca = PCA(n_components=10)\n",
    "\n",
    "pca_X = pca.fit_transform(X)\n",
    "pca_df = pd.DataFrame(data= pca_X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1312"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_dummies.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': np.linspace(0, 1, 10),\n",
    "    'max_depth': np.arange(2, 10, 2),\n",
    "    'n_estimators': np.arange(0, 300, 25),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = np.sqrt(mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3448.7612690844267"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = mean_absolute_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2052.3952956327107"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = GridSearchCV(XGBRegressor(), param_grid=params, scoring='neg_root_mean_squared_error', n_jobs=-1, cv=3, verbose=1)\n",
    "# cv.fit(X_train, y_train)\n",
    "# print(cv.best_params_)\n",
    "# print(cv.best_score_)\n",
    "# best_score = str(cv.best_score_)\n",
    "\n",
    "# with open('params_list.txt', 'a') as file:\n",
    "#     for key,value in cv.best_params_.items():\n",
    "#         file.write(key + \": \" + str(value))\n",
    "#         file.write(\"\\n\")\n",
    "#     file.write(\"Best RMSE Score: \" + best_score)\n",
    "#     file.write(\"\\n\")\n",
    "#     file.write(\"----------------------------------\")\n",
    "#     file.write(\"\\n\")\n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('params_list.txt', 'r') as file:\n",
    "#     for line in file.readlines():\n",
    "#         print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = cv.predict(X_test)\n",
    "# RMSE = np.sqrt(mean_squared_error(y_test, preds))\n",
    "# print(\"RMSE: -- \", RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE_list = []\n",
    "# for i in range(99, 120):\n",
    "#     for j in range(1,20):\n",
    "\n",
    "#         rf = RandomForestRegressor(n_estimators=i, max_depth=j)\n",
    "#         rf.fit(X_train, y_train)\n",
    "#         pred = rf.predict(X_test)\n",
    "#         RMSE = np.sqrt(mean_squared_error(y_test, pred))\n",
    "#         data = {\n",
    "#             'RMSE': RMSE,\n",
    "#             'max_depth': j,\n",
    "#             'n_estimators': i,\n",
    "#         }\n",
    "#         RMSE_list.append(data)\n",
    "#         print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv = RandomizedSearchCV(RandomForestRegressor(), param_distributions={'max_depth': range(1, 25), 'n_estimators': range(1,250, 5)}, n_jobs=-1, n_iter=1000, verbose=1, scoring='neg_root_mean_squared_error', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1000 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\abclay\\Desktop\\Car-Appraisal-Master\\CarvanaEDA\\CarvanaModelTraining.ipynb Cell 30'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/abclay/Desktop/Car-Appraisal-Master/CarvanaEDA/CarvanaModelTraining.ipynb#ch0000075?line=0'>1</a>\u001b[0m rf_cv\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\abclay\\Desktop\\Car-Appraisal-Master\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=884'>885</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=885'>886</a>\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=886'>887</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=888'>889</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=890'>891</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=892'>893</a>\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=893'>894</a>\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=894'>895</a>\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\abclay\\Desktop\\Car-Appraisal-Master\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1766\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=1763'>1764</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=1764'>1765</a>\u001b[0m     \u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=1765'>1766</a>\u001b[0m     evaluate_candidates(\n\u001b[0;32m   <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=1766'>1767</a>\u001b[0m         ParameterSampler(\n\u001b[0;32m   <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=1767'>1768</a>\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[0;32m   <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=1768'>1769</a>\u001b[0m         )\n\u001b[0;32m   <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=1769'>1770</a>\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\abclay\\Desktop\\Car-Appraisal-Master\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=829'>830</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=830'>831</a>\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=831'>832</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=832'>833</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=833'>834</a>\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=834'>835</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=835'>836</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=837'>838</a>\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=838'>839</a>\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=839'>840</a>\u001b[0m         clone(base_estimator),\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=840'>841</a>\u001b[0m         X,\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=841'>842</a>\u001b[0m         y,\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=842'>843</a>\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=843'>844</a>\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=844'>845</a>\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=845'>846</a>\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=846'>847</a>\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=847'>848</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=848'>849</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=849'>850</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=850'>851</a>\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=851'>852</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=852'>853</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=854'>855</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=855'>856</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=856'>857</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=857'>858</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=858'>859</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/sklearn/model_selection/_search.py?line=859'>860</a>\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\abclay\\Desktop\\Car-Appraisal-Master\\venv\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/joblib/parallel.py?line=1052'>1053</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/joblib/parallel.py?line=1054'>1055</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/joblib/parallel.py?line=1055'>1056</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/joblib/parallel.py?line=1056'>1057</a>\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/joblib/parallel.py?line=1057'>1058</a>\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\abclay\\Desktop\\Car-Appraisal-Master\\venv\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/joblib/parallel.py?line=932'>933</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/joblib/parallel.py?line=933'>934</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/joblib/parallel.py?line=934'>935</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/joblib/parallel.py?line=935'>936</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/joblib/parallel.py?line=936'>937</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\abclay\\Desktop\\Car-Appraisal-Master\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/joblib/_parallel_backends.py?line=538'>539</a>\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/joblib/_parallel_backends.py?line=539'>540</a>\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/joblib/_parallel_backends.py?line=540'>541</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/joblib/_parallel_backends.py?line=541'>542</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/joblib/_parallel_backends.py?line=542'>543</a>\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/abclay/Desktop/Car-Appraisal-Master/venv/lib/site-packages/joblib/_parallel_backends.py?line=543'>544</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.752.0_x64__qbz5n2kfra8p0\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.10_3.10.752.0_x64__qbz5n2kfra8p0/lib/concurrent/futures/_base.py?line=437'>438</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.10_3.10.752.0_x64__qbz5n2kfra8p0/lib/concurrent/futures/_base.py?line=438'>439</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.10_3.10.752.0_x64__qbz5n2kfra8p0/lib/concurrent/futures/_base.py?line=440'>441</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.10_3.10.752.0_x64__qbz5n2kfra8p0/lib/concurrent/futures/_base.py?line=442'>443</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.10_3.10.752.0_x64__qbz5n2kfra8p0/lib/concurrent/futures/_base.py?line=443'>444</a>\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.752.0_x64__qbz5n2kfra8p0\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.10_3.10.752.0_x64__qbz5n2kfra8p0/lib/threading.py?line=317'>318</a>\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.10_3.10.752.0_x64__qbz5n2kfra8p0/lib/threading.py?line=318'>319</a>\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.10_3.10.752.0_x64__qbz5n2kfra8p0/lib/threading.py?line=319'>320</a>\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.10_3.10.752.0_x64__qbz5n2kfra8p0/lib/threading.py?line=320'>321</a>\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/WindowsApps/PythonSoftwareFoundation.Python.3.10_3.10.752.0_x64__qbz5n2kfra8p0/lib/threading.py?line=321'>322</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(RMSE_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I will begin the Tensorflow workflow from the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.ylim([0, 10])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [MPG]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dummies.drop('price', axis=1).to_numpy()\n",
    "y = df_dummies['price'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('./checkpoints', monitor=\"mean_absolute_error\", verbose=1, save_best_only=True, save_weights_only=True, mode=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer.adapt(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = Sequential([\n",
    "    normalizer,\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(.5),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.1), loss='mean_absolute_error', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "144/146 [============================>.] - ETA: 0s - loss: 14289.6348 - mean_absolute_error: 14289.6348\n",
      "Epoch 1: mean_absolute_error improved from inf to 14245.38184, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 1s 3ms/step - loss: 14245.3818 - mean_absolute_error: 14245.3818 - val_loss: 10463.3262 - val_mean_absolute_error: 10463.3262\n",
      "Epoch 2/500\n",
      "128/146 [=========================>....] - ETA: 0s - loss: 11604.1455 - mean_absolute_error: 11604.1455\n",
      "Epoch 2: mean_absolute_error improved from 14245.38184 to 11589.47363, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11589.4736 - mean_absolute_error: 11589.4736 - val_loss: 7121.8491 - val_mean_absolute_error: 7121.8491\n",
      "Epoch 3/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 11399.1523 - mean_absolute_error: 11399.1523\n",
      "Epoch 3: mean_absolute_error improved from 11589.47363 to 11399.09375, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 11399.0938 - mean_absolute_error: 11399.0938 - val_loss: 8264.2314 - val_mean_absolute_error: 8264.2314\n",
      "Epoch 4/500\n",
      "136/146 [==========================>...] - ETA: 0s - loss: 11537.0674 - mean_absolute_error: 11537.0674\n",
      "Epoch 4: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11545.4033 - mean_absolute_error: 11545.4033 - val_loss: 11793.8730 - val_mean_absolute_error: 11793.8730\n",
      "Epoch 5/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 12561.1377 - mean_absolute_error: 12561.1377\n",
      "Epoch 5: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 12514.1396 - mean_absolute_error: 12514.1396 - val_loss: 11844.7812 - val_mean_absolute_error: 11844.7812\n",
      "Epoch 6/500\n",
      "125/146 [========================>.....] - ETA: 0s - loss: 12288.0342 - mean_absolute_error: 12288.0342\n",
      "Epoch 6: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 12431.6113 - mean_absolute_error: 12431.6113 - val_loss: 16352.5068 - val_mean_absolute_error: 16352.5068\n",
      "Epoch 7/500\n",
      "144/146 [============================>.] - ETA: 0s - loss: 12686.4717 - mean_absolute_error: 12686.4717\n",
      "Epoch 7: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 12705.2314 - mean_absolute_error: 12705.2314 - val_loss: 11621.3887 - val_mean_absolute_error: 11621.3887\n",
      "Epoch 8/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 12271.5801 - mean_absolute_error: 12271.5801\n",
      "Epoch 8: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 12262.0195 - mean_absolute_error: 12262.0195 - val_loss: 9369.4629 - val_mean_absolute_error: 9369.4629\n",
      "Epoch 9/500\n",
      "143/146 [============================>.] - ETA: 0s - loss: 12536.3184 - mean_absolute_error: 12536.3184\n",
      "Epoch 9: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 12534.1719 - mean_absolute_error: 12534.1719 - val_loss: 10548.1367 - val_mean_absolute_error: 10548.1367\n",
      "Epoch 10/500\n",
      "131/146 [=========================>....] - ETA: 0s - loss: 12482.3809 - mean_absolute_error: 12482.3809\n",
      "Epoch 10: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 12442.6699 - mean_absolute_error: 12442.6699 - val_loss: 14208.1455 - val_mean_absolute_error: 14208.1455\n",
      "Epoch 11/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 12741.4893 - mean_absolute_error: 12741.4893\n",
      "Epoch 11: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 12748.2031 - mean_absolute_error: 12748.2031 - val_loss: 7201.1416 - val_mean_absolute_error: 7201.1416\n",
      "Epoch 12/500\n",
      "136/146 [==========================>...] - ETA: 0s - loss: 12814.1807 - mean_absolute_error: 12814.1807\n",
      "Epoch 12: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 12773.8418 - mean_absolute_error: 12773.8418 - val_loss: 16200.6650 - val_mean_absolute_error: 16200.6650\n",
      "Epoch 13/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 12916.8701 - mean_absolute_error: 12916.8701\n",
      "Epoch 13: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 12805.5977 - mean_absolute_error: 12805.5977 - val_loss: 8870.1992 - val_mean_absolute_error: 8870.1992\n",
      "Epoch 14/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 12662.1982 - mean_absolute_error: 12662.1982\n",
      "Epoch 14: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 12664.9678 - mean_absolute_error: 12664.9678 - val_loss: 13482.7803 - val_mean_absolute_error: 13482.7803\n",
      "Epoch 15/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 12466.6152 - mean_absolute_error: 12466.6152\n",
      "Epoch 15: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 12548.3184 - mean_absolute_error: 12548.3184 - val_loss: 12330.8887 - val_mean_absolute_error: 12330.8887\n",
      "Epoch 16/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 12732.7969 - mean_absolute_error: 12732.7969\n",
      "Epoch 16: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 12659.2607 - mean_absolute_error: 12659.2607 - val_loss: 10723.5723 - val_mean_absolute_error: 10723.5723\n",
      "Epoch 17/500\n",
      "143/146 [============================>.] - ETA: 0s - loss: 12666.2168 - mean_absolute_error: 12666.2168\n",
      "Epoch 17: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 12666.2627 - mean_absolute_error: 12666.2627 - val_loss: 12655.6807 - val_mean_absolute_error: 12655.6807\n",
      "Epoch 18/500\n",
      "125/146 [========================>.....] - ETA: 0s - loss: 12448.1055 - mean_absolute_error: 12448.1055\n",
      "Epoch 18: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 12533.3623 - mean_absolute_error: 12533.3623 - val_loss: 12534.7773 - val_mean_absolute_error: 12534.7773\n",
      "Epoch 19/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 12294.1006 - mean_absolute_error: 12294.1006\n",
      "Epoch 19: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 12278.4414 - mean_absolute_error: 12278.4414 - val_loss: 13097.7178 - val_mean_absolute_error: 13097.7178\n",
      "Epoch 20/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 12735.0674 - mean_absolute_error: 12735.0674\n",
      "Epoch 20: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 12672.8750 - mean_absolute_error: 12672.8750 - val_loss: 14801.1846 - val_mean_absolute_error: 14801.1846\n",
      "Epoch 21/500\n",
      "124/146 [========================>.....] - ETA: 0s - loss: 12687.4834 - mean_absolute_error: 12687.4834\n",
      "Epoch 21: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 12741.4727 - mean_absolute_error: 12741.4727 - val_loss: 13921.6816 - val_mean_absolute_error: 13921.6816\n",
      "Epoch 22/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 13166.4707 - mean_absolute_error: 13166.4707\n",
      "Epoch 22: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 13013.5156 - mean_absolute_error: 13013.5156 - val_loss: 13619.6816 - val_mean_absolute_error: 13619.6816\n",
      "Epoch 23/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 11896.5254 - mean_absolute_error: 11896.5254\n",
      "Epoch 23: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11886.9082 - mean_absolute_error: 11886.9082 - val_loss: 16172.6963 - val_mean_absolute_error: 16172.6963\n",
      "Epoch 24/500\n",
      "128/146 [=========================>....] - ETA: 0s - loss: 12217.7773 - mean_absolute_error: 12217.7773\n",
      "Epoch 24: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 12216.8027 - mean_absolute_error: 12216.8027 - val_loss: 13456.1299 - val_mean_absolute_error: 13456.1299\n",
      "Epoch 25/500\n",
      "141/146 [===========================>..] - ETA: 0s - loss: 12101.1875 - mean_absolute_error: 12101.1875\n",
      "Epoch 25: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 12116.5303 - mean_absolute_error: 12116.5303 - val_loss: 11646.4590 - val_mean_absolute_error: 11646.4590\n",
      "Epoch 26/500\n",
      "117/146 [=======================>......] - ETA: 0s - loss: 12348.3379 - mean_absolute_error: 12348.3379\n",
      "Epoch 26: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 12352.0098 - mean_absolute_error: 12352.0098 - val_loss: 12229.5234 - val_mean_absolute_error: 12229.5234\n",
      "Epoch 27/500\n",
      "121/146 [=======================>......] - ETA: 0s - loss: 11673.6152 - mean_absolute_error: 11673.6152\n",
      "Epoch 27: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11731.1182 - mean_absolute_error: 11731.1182 - val_loss: 16097.7363 - val_mean_absolute_error: 16097.7363\n",
      "Epoch 28/500\n",
      "115/146 [======================>.......] - ETA: 0s - loss: 11884.3525 - mean_absolute_error: 11884.3525\n",
      "Epoch 28: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11874.3428 - mean_absolute_error: 11874.3428 - val_loss: 9406.1406 - val_mean_absolute_error: 9406.1406\n",
      "Epoch 29/500\n",
      "136/146 [==========================>...] - ETA: 0s - loss: 12231.5117 - mean_absolute_error: 12231.5117\n",
      "Epoch 29: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 12262.4023 - mean_absolute_error: 12262.4023 - val_loss: 16024.3994 - val_mean_absolute_error: 16024.3994\n",
      "Epoch 30/500\n",
      "128/146 [=========================>....] - ETA: 0s - loss: 12119.5742 - mean_absolute_error: 12119.5742\n",
      "Epoch 30: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 12070.9307 - mean_absolute_error: 12070.9307 - val_loss: 11927.3672 - val_mean_absolute_error: 11927.3672\n",
      "Epoch 31/500\n",
      "131/146 [=========================>....] - ETA: 0s - loss: 13044.6064 - mean_absolute_error: 13044.6064\n",
      "Epoch 31: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 12915.8037 - mean_absolute_error: 12915.8037 - val_loss: 7718.7095 - val_mean_absolute_error: 7718.7095\n",
      "Epoch 32/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 12269.5195 - mean_absolute_error: 12269.5195\n",
      "Epoch 32: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 12269.9121 - mean_absolute_error: 12269.9121 - val_loss: 13973.1895 - val_mean_absolute_error: 13973.1895\n",
      "Epoch 33/500\n",
      "122/146 [========================>.....] - ETA: 0s - loss: 12271.7363 - mean_absolute_error: 12271.7363\n",
      "Epoch 33: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 12180.5625 - mean_absolute_error: 12180.5625 - val_loss: 13509.5107 - val_mean_absolute_error: 13509.5107\n",
      "Epoch 34/500\n",
      "118/146 [=======================>......] - ETA: 0s - loss: 11642.2266 - mean_absolute_error: 11642.2266\n",
      "Epoch 34: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11644.3877 - mean_absolute_error: 11644.3877 - val_loss: 11677.6846 - val_mean_absolute_error: 11677.6846\n",
      "Epoch 35/500\n",
      "120/146 [=======================>......] - ETA: 0s - loss: 11698.3975 - mean_absolute_error: 11698.3975\n",
      "Epoch 35: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11789.4209 - mean_absolute_error: 11789.4209 - val_loss: 14595.4277 - val_mean_absolute_error: 14595.4277\n",
      "Epoch 36/500\n",
      "131/146 [=========================>....] - ETA: 0s - loss: 11774.1670 - mean_absolute_error: 11774.1670\n",
      "Epoch 36: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11798.0195 - mean_absolute_error: 11798.0195 - val_loss: 11414.1543 - val_mean_absolute_error: 11414.1543\n",
      "Epoch 37/500\n",
      "136/146 [==========================>...] - ETA: 0s - loss: 11884.4990 - mean_absolute_error: 11884.4990\n",
      "Epoch 37: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11849.8066 - mean_absolute_error: 11849.8066 - val_loss: 11061.3252 - val_mean_absolute_error: 11061.3252\n",
      "Epoch 38/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 12031.9707 - mean_absolute_error: 12031.9707\n",
      "Epoch 38: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 12032.9219 - mean_absolute_error: 12032.9219 - val_loss: 10689.7588 - val_mean_absolute_error: 10689.7588\n",
      "Epoch 39/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 11953.0967 - mean_absolute_error: 11953.0967\n",
      "Epoch 39: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11948.1816 - mean_absolute_error: 11948.1816 - val_loss: 12630.8809 - val_mean_absolute_error: 12630.8809\n",
      "Epoch 40/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 12007.9971 - mean_absolute_error: 12007.9971\n",
      "Epoch 40: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 12000.3447 - mean_absolute_error: 12000.3447 - val_loss: 12405.3789 - val_mean_absolute_error: 12405.3789\n",
      "Epoch 41/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 11686.4932 - mean_absolute_error: 11686.4932\n",
      "Epoch 41: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11661.2090 - mean_absolute_error: 11661.2090 - val_loss: 14168.3154 - val_mean_absolute_error: 14168.3154\n",
      "Epoch 42/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 12008.3623 - mean_absolute_error: 12008.3623\n",
      "Epoch 42: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11990.1748 - mean_absolute_error: 11990.1748 - val_loss: 13959.4453 - val_mean_absolute_error: 13959.4453\n",
      "Epoch 43/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 11904.1943 - mean_absolute_error: 11904.1943\n",
      "Epoch 43: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11940.8125 - mean_absolute_error: 11940.8125 - val_loss: 11179.9648 - val_mean_absolute_error: 11179.9648\n",
      "Epoch 44/500\n",
      "146/146 [==============================] - ETA: 0s - loss: 11561.3740 - mean_absolute_error: 11561.3740\n",
      "Epoch 44: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11561.3740 - mean_absolute_error: 11561.3740 - val_loss: 13917.2305 - val_mean_absolute_error: 13917.2305\n",
      "Epoch 45/500\n",
      "131/146 [=========================>....] - ETA: 0s - loss: 11866.0205 - mean_absolute_error: 11866.0205\n",
      "Epoch 45: mean_absolute_error did not improve from 11399.09375\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11777.1133 - mean_absolute_error: 11777.1133 - val_loss: 12113.4756 - val_mean_absolute_error: 12113.4756\n",
      "Epoch 46/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 11296.1318 - mean_absolute_error: 11296.1318\n",
      "Epoch 46: mean_absolute_error improved from 11399.09375 to 11267.66504, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11267.6650 - mean_absolute_error: 11267.6650 - val_loss: 14045.0645 - val_mean_absolute_error: 14045.0645\n",
      "Epoch 47/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 12165.8613 - mean_absolute_error: 12165.8613\n",
      "Epoch 47: mean_absolute_error did not improve from 11267.66504\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 12141.3291 - mean_absolute_error: 12141.3291 - val_loss: 14488.8652 - val_mean_absolute_error: 14488.8652\n",
      "Epoch 48/500\n",
      "143/146 [============================>.] - ETA: 0s - loss: 11877.9834 - mean_absolute_error: 11877.9834\n",
      "Epoch 48: mean_absolute_error did not improve from 11267.66504\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11909.6484 - mean_absolute_error: 11909.6484 - val_loss: 13257.5488 - val_mean_absolute_error: 13257.5488\n",
      "Epoch 49/500\n",
      "146/146 [==============================] - ETA: 0s - loss: 11642.7939 - mean_absolute_error: 11642.7939\n",
      "Epoch 49: mean_absolute_error did not improve from 11267.66504\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11642.7939 - mean_absolute_error: 11642.7939 - val_loss: 11246.1016 - val_mean_absolute_error: 11246.1016\n",
      "Epoch 50/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 11731.6035 - mean_absolute_error: 11731.6035\n",
      "Epoch 50: mean_absolute_error did not improve from 11267.66504\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11727.5986 - mean_absolute_error: 11727.5986 - val_loss: 14398.3174 - val_mean_absolute_error: 14398.3174\n",
      "Epoch 51/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 11596.5146 - mean_absolute_error: 11596.5146\n",
      "Epoch 51: mean_absolute_error did not improve from 11267.66504\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11620.8008 - mean_absolute_error: 11620.8008 - val_loss: 12591.4912 - val_mean_absolute_error: 12591.4912\n",
      "Epoch 52/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 11300.4102 - mean_absolute_error: 11300.4102\n",
      "Epoch 52: mean_absolute_error improved from 11267.66504 to 11223.72363, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11223.7236 - mean_absolute_error: 11223.7236 - val_loss: 12300.3359 - val_mean_absolute_error: 12300.3359\n",
      "Epoch 53/500\n",
      "124/146 [========================>.....] - ETA: 0s - loss: 11520.2080 - mean_absolute_error: 11520.2080\n",
      "Epoch 53: mean_absolute_error did not improve from 11223.72363\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11481.7451 - mean_absolute_error: 11481.7451 - val_loss: 12492.4893 - val_mean_absolute_error: 12492.4893\n",
      "Epoch 54/500\n",
      "131/146 [=========================>....] - ETA: 0s - loss: 11362.6729 - mean_absolute_error: 11362.6729\n",
      "Epoch 54: mean_absolute_error did not improve from 11223.72363\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11326.6982 - mean_absolute_error: 11326.6982 - val_loss: 13128.3193 - val_mean_absolute_error: 13128.3193\n",
      "Epoch 55/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 11303.1768 - mean_absolute_error: 11303.1768\n",
      "Epoch 55: mean_absolute_error did not improve from 11223.72363\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11253.3223 - mean_absolute_error: 11253.3223 - val_loss: 11313.4570 - val_mean_absolute_error: 11313.4570\n",
      "Epoch 56/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 11556.4648 - mean_absolute_error: 11556.4648\n",
      "Epoch 56: mean_absolute_error did not improve from 11223.72363\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11590.1191 - mean_absolute_error: 11590.1191 - val_loss: 13356.6240 - val_mean_absolute_error: 13356.6240\n",
      "Epoch 57/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 11634.3613 - mean_absolute_error: 11634.3613\n",
      "Epoch 57: mean_absolute_error did not improve from 11223.72363\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11646.3320 - mean_absolute_error: 11646.3320 - val_loss: 15007.3525 - val_mean_absolute_error: 15007.3525\n",
      "Epoch 58/500\n",
      "143/146 [============================>.] - ETA: 0s - loss: 11741.4873 - mean_absolute_error: 11741.4873\n",
      "Epoch 58: mean_absolute_error did not improve from 11223.72363\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11748.4404 - mean_absolute_error: 11748.4404 - val_loss: 14242.2021 - val_mean_absolute_error: 14242.2021\n",
      "Epoch 59/500\n",
      "126/146 [========================>.....] - ETA: 0s - loss: 11492.4824 - mean_absolute_error: 11492.4824\n",
      "Epoch 59: mean_absolute_error did not improve from 11223.72363\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11614.5830 - mean_absolute_error: 11614.5830 - val_loss: 12405.6279 - val_mean_absolute_error: 12405.6279\n",
      "Epoch 60/500\n",
      "128/146 [=========================>....] - ETA: 0s - loss: 11313.1230 - mean_absolute_error: 11313.1230\n",
      "Epoch 60: mean_absolute_error did not improve from 11223.72363\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11345.3691 - mean_absolute_error: 11345.3691 - val_loss: 13240.5947 - val_mean_absolute_error: 13240.5947\n",
      "Epoch 61/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 12075.6943 - mean_absolute_error: 12075.6943\n",
      "Epoch 61: mean_absolute_error did not improve from 11223.72363\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11988.9912 - mean_absolute_error: 11988.9912 - val_loss: 14565.2969 - val_mean_absolute_error: 14565.2969\n",
      "Epoch 62/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 11489.4424 - mean_absolute_error: 11489.4424\n",
      "Epoch 62: mean_absolute_error did not improve from 11223.72363\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11567.8369 - mean_absolute_error: 11567.8369 - val_loss: 14715.1787 - val_mean_absolute_error: 14715.1787\n",
      "Epoch 63/500\n",
      "117/146 [=======================>......] - ETA: 0s - loss: 11259.4648 - mean_absolute_error: 11259.4648\n",
      "Epoch 63: mean_absolute_error did not improve from 11223.72363\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11251.8770 - mean_absolute_error: 11251.8770 - val_loss: 13819.8262 - val_mean_absolute_error: 13819.8262\n",
      "Epoch 64/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 11363.8418 - mean_absolute_error: 11363.8418\n",
      "Epoch 64: mean_absolute_error did not improve from 11223.72363\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11350.3105 - mean_absolute_error: 11350.3105 - val_loss: 13055.1279 - val_mean_absolute_error: 13055.1279\n",
      "Epoch 65/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 11723.1758 - mean_absolute_error: 11723.1758\n",
      "Epoch 65: mean_absolute_error did not improve from 11223.72363\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11650.9785 - mean_absolute_error: 11650.9785 - val_loss: 13733.8828 - val_mean_absolute_error: 13733.8828\n",
      "Epoch 66/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 11116.3926 - mean_absolute_error: 11116.3926\n",
      "Epoch 66: mean_absolute_error improved from 11223.72363 to 11151.08008, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11151.0801 - mean_absolute_error: 11151.0801 - val_loss: 11632.3340 - val_mean_absolute_error: 11632.3340\n",
      "Epoch 67/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 11235.0293 - mean_absolute_error: 11235.0293\n",
      "Epoch 67: mean_absolute_error did not improve from 11151.08008\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11272.5957 - mean_absolute_error: 11272.5957 - val_loss: 15094.3428 - val_mean_absolute_error: 15094.3428\n",
      "Epoch 68/500\n",
      "126/146 [========================>.....] - ETA: 0s - loss: 11199.3252 - mean_absolute_error: 11199.3252\n",
      "Epoch 68: mean_absolute_error did not improve from 11151.08008\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11232.4746 - mean_absolute_error: 11232.4746 - val_loss: 14139.4697 - val_mean_absolute_error: 14139.4697\n",
      "Epoch 69/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 11651.2627 - mean_absolute_error: 11651.2627\n",
      "Epoch 69: mean_absolute_error did not improve from 11151.08008\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11538.4199 - mean_absolute_error: 11538.4199 - val_loss: 10825.0273 - val_mean_absolute_error: 10825.0273\n",
      "Epoch 70/500\n",
      "125/146 [========================>.....] - ETA: 0s - loss: 11311.8320 - mean_absolute_error: 11311.8320\n",
      "Epoch 70: mean_absolute_error did not improve from 11151.08008\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11293.3291 - mean_absolute_error: 11293.3291 - val_loss: 15142.7881 - val_mean_absolute_error: 15142.7881\n",
      "Epoch 71/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 11281.8359 - mean_absolute_error: 11281.8359\n",
      "Epoch 71: mean_absolute_error did not improve from 11151.08008\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11267.5635 - mean_absolute_error: 11267.5635 - val_loss: 11015.4502 - val_mean_absolute_error: 11015.4502\n",
      "Epoch 72/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 11846.1416 - mean_absolute_error: 11846.1416\n",
      "Epoch 72: mean_absolute_error did not improve from 11151.08008\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11841.1689 - mean_absolute_error: 11841.1689 - val_loss: 16439.6289 - val_mean_absolute_error: 16439.6289\n",
      "Epoch 73/500\n",
      "143/146 [============================>.] - ETA: 0s - loss: 11867.4502 - mean_absolute_error: 11867.4502\n",
      "Epoch 73: mean_absolute_error did not improve from 11151.08008\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11893.1318 - mean_absolute_error: 11893.1318 - val_loss: 13811.1367 - val_mean_absolute_error: 13811.1367\n",
      "Epoch 74/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 11475.1260 - mean_absolute_error: 11475.1260\n",
      "Epoch 74: mean_absolute_error did not improve from 11151.08008\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11496.0938 - mean_absolute_error: 11496.0938 - val_loss: 13863.7695 - val_mean_absolute_error: 13863.7695\n",
      "Epoch 75/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 11196.0430 - mean_absolute_error: 11196.0430\n",
      "Epoch 75: mean_absolute_error improved from 11151.08008 to 11141.16895, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11141.1689 - mean_absolute_error: 11141.1689 - val_loss: 17140.6719 - val_mean_absolute_error: 17140.6719\n",
      "Epoch 76/500\n",
      "126/146 [========================>.....] - ETA: 0s - loss: 11727.4268 - mean_absolute_error: 11727.4268\n",
      "Epoch 76: mean_absolute_error did not improve from 11141.16895\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11820.3096 - mean_absolute_error: 11820.3096 - val_loss: 14031.3574 - val_mean_absolute_error: 14031.3574\n",
      "Epoch 77/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 11805.9180 - mean_absolute_error: 11805.9180\n",
      "Epoch 77: mean_absolute_error did not improve from 11141.16895\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11646.5488 - mean_absolute_error: 11646.5488 - val_loss: 11817.8984 - val_mean_absolute_error: 11817.8984\n",
      "Epoch 78/500\n",
      "144/146 [============================>.] - ETA: 0s - loss: 11402.5879 - mean_absolute_error: 11402.5879\n",
      "Epoch 78: mean_absolute_error did not improve from 11141.16895\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11409.4893 - mean_absolute_error: 11409.4893 - val_loss: 11405.2422 - val_mean_absolute_error: 11405.2422\n",
      "Epoch 79/500\n",
      "145/146 [============================>.] - ETA: 0s - loss: 11558.5430 - mean_absolute_error: 11558.5430\n",
      "Epoch 79: mean_absolute_error did not improve from 11141.16895\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11566.1348 - mean_absolute_error: 11566.1348 - val_loss: 15263.7021 - val_mean_absolute_error: 15263.7021\n",
      "Epoch 80/500\n",
      "145/146 [============================>.] - ETA: 0s - loss: 11166.6562 - mean_absolute_error: 11166.6562\n",
      "Epoch 80: mean_absolute_error did not improve from 11141.16895\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 11172.2549 - mean_absolute_error: 11172.2549 - val_loss: 12251.8389 - val_mean_absolute_error: 12251.8389\n",
      "Epoch 81/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 11114.0938 - mean_absolute_error: 11114.0938\n",
      "Epoch 81: mean_absolute_error improved from 11141.16895 to 11095.95020, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 11095.9502 - mean_absolute_error: 11095.9502 - val_loss: 11804.5762 - val_mean_absolute_error: 11804.5762\n",
      "Epoch 82/500\n",
      "131/146 [=========================>....] - ETA: 0s - loss: 10871.4258 - mean_absolute_error: 10871.4258\n",
      "Epoch 82: mean_absolute_error improved from 11095.95020 to 10860.15723, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 10860.1572 - mean_absolute_error: 10860.1572 - val_loss: 13812.0146 - val_mean_absolute_error: 13812.0146\n",
      "Epoch 83/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 10874.4570 - mean_absolute_error: 10874.4570\n",
      "Epoch 83: mean_absolute_error improved from 10860.15723 to 10834.99707, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 10834.9971 - mean_absolute_error: 10834.9971 - val_loss: 14996.1768 - val_mean_absolute_error: 14996.1768\n",
      "Epoch 84/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 10435.8818 - mean_absolute_error: 10435.8818\n",
      "Epoch 84: mean_absolute_error improved from 10834.99707 to 10416.34277, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 10416.3428 - mean_absolute_error: 10416.3428 - val_loss: 14291.2949 - val_mean_absolute_error: 14291.2949\n",
      "Epoch 85/500\n",
      "126/146 [========================>.....] - ETA: 0s - loss: 10194.0752 - mean_absolute_error: 10194.0752\n",
      "Epoch 85: mean_absolute_error improved from 10416.34277 to 10218.74023, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 10218.7402 - mean_absolute_error: 10218.7402 - val_loss: 12967.6982 - val_mean_absolute_error: 12967.6982\n",
      "Epoch 86/500\n",
      "136/146 [==========================>...] - ETA: 0s - loss: 10651.3691 - mean_absolute_error: 10651.3691\n",
      "Epoch 86: mean_absolute_error did not improve from 10218.74023\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 10609.1455 - mean_absolute_error: 10609.1455 - val_loss: 11007.0527 - val_mean_absolute_error: 11007.0527\n",
      "Epoch 87/500\n",
      "128/146 [=========================>....] - ETA: 0s - loss: 10484.8545 - mean_absolute_error: 10484.8545\n",
      "Epoch 87: mean_absolute_error did not improve from 10218.74023\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 10384.8320 - mean_absolute_error: 10384.8320 - val_loss: 11448.3740 - val_mean_absolute_error: 11448.3740\n",
      "Epoch 88/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 10545.3916 - mean_absolute_error: 10545.3916\n",
      "Epoch 88: mean_absolute_error did not improve from 10218.74023\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 10444.3984 - mean_absolute_error: 10444.3984 - val_loss: 12848.1143 - val_mean_absolute_error: 12848.1143\n",
      "Epoch 89/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 10304.8965 - mean_absolute_error: 10304.8965\n",
      "Epoch 89: mean_absolute_error did not improve from 10218.74023\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 10340.5645 - mean_absolute_error: 10340.5645 - val_loss: 12820.6338 - val_mean_absolute_error: 12820.6338\n",
      "Epoch 90/500\n",
      "120/146 [=======================>......] - ETA: 0s - loss: 10423.0176 - mean_absolute_error: 10423.0176\n",
      "Epoch 90: mean_absolute_error did not improve from 10218.74023\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 10455.2520 - mean_absolute_error: 10455.2520 - val_loss: 12396.8232 - val_mean_absolute_error: 12396.8232\n",
      "Epoch 91/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 9748.1895 - mean_absolute_error: 9748.1895\n",
      "Epoch 91: mean_absolute_error improved from 10218.74023 to 9683.21484, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 9683.2148 - mean_absolute_error: 9683.2148 - val_loss: 12528.3252 - val_mean_absolute_error: 12528.3252\n",
      "Epoch 92/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 9792.3135 - mean_absolute_error: 9792.3135\n",
      "Epoch 92: mean_absolute_error did not improve from 9683.21484\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 9714.9385 - mean_absolute_error: 9714.9385 - val_loss: 12529.3057 - val_mean_absolute_error: 12529.3057\n",
      "Epoch 93/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 10114.5674 - mean_absolute_error: 10114.5674\n",
      "Epoch 93: mean_absolute_error did not improve from 9683.21484\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 10120.8477 - mean_absolute_error: 10120.8477 - val_loss: 13892.1133 - val_mean_absolute_error: 13892.1133\n",
      "Epoch 94/500\n",
      "124/146 [========================>.....] - ETA: 0s - loss: 10049.9941 - mean_absolute_error: 10049.9941\n",
      "Epoch 94: mean_absolute_error did not improve from 9683.21484\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 10088.8447 - mean_absolute_error: 10088.8447 - val_loss: 12751.0332 - val_mean_absolute_error: 12751.0332\n",
      "Epoch 95/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 9960.3828 - mean_absolute_error: 9960.3828\n",
      "Epoch 95: mean_absolute_error did not improve from 9683.21484\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 9998.6543 - mean_absolute_error: 9998.6543 - val_loss: 13424.1299 - val_mean_absolute_error: 13424.1299\n",
      "Epoch 96/500\n",
      "146/146 [==============================] - ETA: 0s - loss: 9556.2988 - mean_absolute_error: 9556.2988\n",
      "Epoch 96: mean_absolute_error improved from 9683.21484 to 9556.29883, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 9556.2988 - mean_absolute_error: 9556.2988 - val_loss: 12341.7520 - val_mean_absolute_error: 12341.7520\n",
      "Epoch 97/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 9032.2285 - mean_absolute_error: 9032.2285\n",
      "Epoch 97: mean_absolute_error improved from 9556.29883 to 9046.08105, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 9046.0811 - mean_absolute_error: 9046.0811 - val_loss: 13122.3320 - val_mean_absolute_error: 13122.3320\n",
      "Epoch 98/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 8949.8906 - mean_absolute_error: 8949.8906\n",
      "Epoch 98: mean_absolute_error improved from 9046.08105 to 9016.52930, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 9016.5293 - mean_absolute_error: 9016.5293 - val_loss: 13259.0498 - val_mean_absolute_error: 13259.0498\n",
      "Epoch 99/500\n",
      "131/146 [=========================>....] - ETA: 0s - loss: 9279.0283 - mean_absolute_error: 9279.0283\n",
      "Epoch 99: mean_absolute_error did not improve from 9016.52930\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 9195.6084 - mean_absolute_error: 9195.6084 - val_loss: 13075.6523 - val_mean_absolute_error: 13075.6523\n",
      "Epoch 100/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 9249.6318 - mean_absolute_error: 9249.6318\n",
      "Epoch 100: mean_absolute_error did not improve from 9016.52930\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 9266.5479 - mean_absolute_error: 9266.5479 - val_loss: 11953.6738 - val_mean_absolute_error: 11953.6738\n",
      "Epoch 101/500\n",
      "119/146 [=======================>......] - ETA: 0s - loss: 9537.9229 - mean_absolute_error: 9537.9229\n",
      "Epoch 101: mean_absolute_error did not improve from 9016.52930\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 9380.6924 - mean_absolute_error: 9380.6924 - val_loss: 11400.1973 - val_mean_absolute_error: 11400.1973\n",
      "Epoch 102/500\n",
      "126/146 [========================>.....] - ETA: 0s - loss: 8881.1621 - mean_absolute_error: 8881.1621\n",
      "Epoch 102: mean_absolute_error improved from 9016.52930 to 8908.11523, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 8908.1152 - mean_absolute_error: 8908.1152 - val_loss: 12185.1338 - val_mean_absolute_error: 12185.1338\n",
      "Epoch 103/500\n",
      "131/146 [=========================>....] - ETA: 0s - loss: 8782.4756 - mean_absolute_error: 8782.4756\n",
      "Epoch 103: mean_absolute_error improved from 8908.11523 to 8709.69141, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 8709.6914 - mean_absolute_error: 8709.6914 - val_loss: 11814.6807 - val_mean_absolute_error: 11814.6807\n",
      "Epoch 104/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 8508.2266 - mean_absolute_error: 8508.2266\n",
      "Epoch 104: mean_absolute_error improved from 8709.69141 to 8522.79688, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 8522.7969 - mean_absolute_error: 8522.7969 - val_loss: 12176.2207 - val_mean_absolute_error: 12176.2207\n",
      "Epoch 105/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 8483.9365 - mean_absolute_error: 8483.9365\n",
      "Epoch 105: mean_absolute_error improved from 8522.79688 to 8502.15332, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 8502.1533 - mean_absolute_error: 8502.1533 - val_loss: 11341.2744 - val_mean_absolute_error: 11341.2744\n",
      "Epoch 106/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 8403.8008 - mean_absolute_error: 8403.8008\n",
      "Epoch 106: mean_absolute_error improved from 8502.15332 to 8390.63281, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 8390.6328 - mean_absolute_error: 8390.6328 - val_loss: 10702.8906 - val_mean_absolute_error: 10702.8906\n",
      "Epoch 107/500\n",
      "145/146 [============================>.] - ETA: 0s - loss: 8341.5615 - mean_absolute_error: 8341.5615\n",
      "Epoch 107: mean_absolute_error improved from 8390.63281 to 8356.10742, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 8356.1074 - mean_absolute_error: 8356.1074 - val_loss: 12364.3125 - val_mean_absolute_error: 12364.3125\n",
      "Epoch 108/500\n",
      "143/146 [============================>.] - ETA: 0s - loss: 8438.4463 - mean_absolute_error: 8438.4463\n",
      "Epoch 108: mean_absolute_error did not improve from 8356.10742\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 8432.1016 - mean_absolute_error: 8432.1016 - val_loss: 10709.0439 - val_mean_absolute_error: 10709.0439\n",
      "Epoch 109/500\n",
      "143/146 [============================>.] - ETA: 0s - loss: 8417.0176 - mean_absolute_error: 8417.0176\n",
      "Epoch 109: mean_absolute_error did not improve from 8356.10742\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 8420.8506 - mean_absolute_error: 8420.8506 - val_loss: 11036.3457 - val_mean_absolute_error: 11036.3457\n",
      "Epoch 110/500\n",
      "136/146 [==========================>...] - ETA: 0s - loss: 8529.6211 - mean_absolute_error: 8529.6211\n",
      "Epoch 110: mean_absolute_error did not improve from 8356.10742\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 8514.2100 - mean_absolute_error: 8514.2100 - val_loss: 12552.0850 - val_mean_absolute_error: 12552.0850\n",
      "Epoch 111/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 8345.3818 - mean_absolute_error: 8345.3818\n",
      "Epoch 111: mean_absolute_error improved from 8356.10742 to 8328.06641, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 8328.0664 - mean_absolute_error: 8328.0664 - val_loss: 11028.7256 - val_mean_absolute_error: 11028.7256\n",
      "Epoch 112/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 8397.2188 - mean_absolute_error: 8397.2188\n",
      "Epoch 112: mean_absolute_error did not improve from 8328.06641\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 8340.5947 - mean_absolute_error: 8340.5947 - val_loss: 11964.7119 - val_mean_absolute_error: 11964.7119\n",
      "Epoch 113/500\n",
      "128/146 [=========================>....] - ETA: 0s - loss: 8391.8359 - mean_absolute_error: 8391.8359\n",
      "Epoch 113: mean_absolute_error did not improve from 8328.06641\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 8333.6465 - mean_absolute_error: 8333.6465 - val_loss: 11465.9541 - val_mean_absolute_error: 11465.9541\n",
      "Epoch 114/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 8214.1572 - mean_absolute_error: 8214.1572\n",
      "Epoch 114: mean_absolute_error improved from 8328.06641 to 8273.31250, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 8273.3125 - mean_absolute_error: 8273.3125 - val_loss: 11539.0596 - val_mean_absolute_error: 11539.0596\n",
      "Epoch 115/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 8494.8359 - mean_absolute_error: 8494.8359\n",
      "Epoch 115: mean_absolute_error did not improve from 8273.31250\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 8457.3906 - mean_absolute_error: 8457.3906 - val_loss: 10020.4053 - val_mean_absolute_error: 10020.4053\n",
      "Epoch 116/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 8462.4619 - mean_absolute_error: 8462.4619\n",
      "Epoch 116: mean_absolute_error did not improve from 8273.31250\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 8491.4600 - mean_absolute_error: 8491.4600 - val_loss: 9900.6504 - val_mean_absolute_error: 9900.6504\n",
      "Epoch 117/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 8413.5186 - mean_absolute_error: 8413.5186\n",
      "Epoch 117: mean_absolute_error did not improve from 8273.31250\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 8418.1914 - mean_absolute_error: 8418.1914 - val_loss: 10911.6426 - val_mean_absolute_error: 10911.6426\n",
      "Epoch 118/500\n",
      "120/146 [=======================>......] - ETA: 0s - loss: 8390.0713 - mean_absolute_error: 8390.0713\n",
      "Epoch 118: mean_absolute_error did not improve from 8273.31250\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 8352.3174 - mean_absolute_error: 8352.3174 - val_loss: 11404.1230 - val_mean_absolute_error: 11404.1230\n",
      "Epoch 119/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 8293.2100 - mean_absolute_error: 8293.2100\n",
      "Epoch 119: mean_absolute_error improved from 8273.31250 to 8271.63281, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 8271.6328 - mean_absolute_error: 8271.6328 - val_loss: 9823.7910 - val_mean_absolute_error: 9823.7910\n",
      "Epoch 120/500\n",
      "143/146 [============================>.] - ETA: 0s - loss: 8582.4912 - mean_absolute_error: 8582.4912\n",
      "Epoch 120: mean_absolute_error did not improve from 8271.63281\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 8573.6064 - mean_absolute_error: 8573.6064 - val_loss: 8250.9746 - val_mean_absolute_error: 8250.9746\n",
      "Epoch 121/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 8462.2939 - mean_absolute_error: 8462.2939\n",
      "Epoch 121: mean_absolute_error did not improve from 8271.63281\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 8466.8887 - mean_absolute_error: 8466.8887 - val_loss: 10995.2998 - val_mean_absolute_error: 10995.2998\n",
      "Epoch 122/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 8609.4189 - mean_absolute_error: 8609.4189\n",
      "Epoch 122: mean_absolute_error did not improve from 8271.63281\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 8519.6035 - mean_absolute_error: 8519.6035 - val_loss: 9880.5049 - val_mean_absolute_error: 9880.5049\n",
      "Epoch 123/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 8533.4736 - mean_absolute_error: 8533.4736\n",
      "Epoch 123: mean_absolute_error did not improve from 8271.63281\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 8524.1572 - mean_absolute_error: 8524.1572 - val_loss: 10913.0342 - val_mean_absolute_error: 10913.0342\n",
      "Epoch 124/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 8376.9316 - mean_absolute_error: 8376.9316\n",
      "Epoch 124: mean_absolute_error did not improve from 8271.63281\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 8426.1934 - mean_absolute_error: 8426.1934 - val_loss: 9492.3408 - val_mean_absolute_error: 9492.3408\n",
      "Epoch 125/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 8322.1914 - mean_absolute_error: 8322.1914\n",
      "Epoch 125: mean_absolute_error did not improve from 8271.63281\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 8289.8584 - mean_absolute_error: 8289.8584 - val_loss: 11205.6084 - val_mean_absolute_error: 11205.6084\n",
      "Epoch 126/500\n",
      "136/146 [==========================>...] - ETA: 0s - loss: 8490.9521 - mean_absolute_error: 8490.9521\n",
      "Epoch 126: mean_absolute_error did not improve from 8271.63281\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 8487.0469 - mean_absolute_error: 8487.0469 - val_loss: 8498.4941 - val_mean_absolute_error: 8498.4941\n",
      "Epoch 127/500\n",
      "120/146 [=======================>......] - ETA: 0s - loss: 8566.2725 - mean_absolute_error: 8566.2725\n",
      "Epoch 127: mean_absolute_error did not improve from 8271.63281\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 8474.9463 - mean_absolute_error: 8474.9463 - val_loss: 8982.0557 - val_mean_absolute_error: 8982.0557\n",
      "Epoch 128/500\n",
      "144/146 [============================>.] - ETA: 0s - loss: 8716.6094 - mean_absolute_error: 8716.6094\n",
      "Epoch 128: mean_absolute_error did not improve from 8271.63281\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 8742.0693 - mean_absolute_error: 8742.0693 - val_loss: 7795.9390 - val_mean_absolute_error: 7795.9390\n",
      "Epoch 129/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7978.2144 - mean_absolute_error: 7978.2144\n",
      "Epoch 129: mean_absolute_error improved from 8271.63281 to 7947.55420, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7947.5542 - mean_absolute_error: 7947.5542 - val_loss: 6717.3940 - val_mean_absolute_error: 6717.3940\n",
      "Epoch 130/500\n",
      "125/146 [========================>.....] - ETA: 0s - loss: 7770.0527 - mean_absolute_error: 7770.0527\n",
      "Epoch 130: mean_absolute_error improved from 7947.55420 to 7767.19971, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7767.1997 - mean_absolute_error: 7767.1997 - val_loss: 6358.1577 - val_mean_absolute_error: 6358.1577\n",
      "Epoch 131/500\n",
      "144/146 [============================>.] - ETA: 0s - loss: 7711.0835 - mean_absolute_error: 7711.0835\n",
      "Epoch 131: mean_absolute_error improved from 7767.19971 to 7701.21338, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7701.2134 - mean_absolute_error: 7701.2134 - val_loss: 6679.6035 - val_mean_absolute_error: 6679.6035\n",
      "Epoch 132/500\n",
      "128/146 [=========================>....] - ETA: 0s - loss: 7739.6978 - mean_absolute_error: 7739.6978\n",
      "Epoch 132: mean_absolute_error did not improve from 7701.21338\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7744.1519 - mean_absolute_error: 7744.1519 - val_loss: 6854.5537 - val_mean_absolute_error: 6854.5537\n",
      "Epoch 133/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 7804.4917 - mean_absolute_error: 7804.4917\n",
      "Epoch 133: mean_absolute_error did not improve from 7701.21338\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7766.9819 - mean_absolute_error: 7766.9819 - val_loss: 7023.9644 - val_mean_absolute_error: 7023.9644\n",
      "Epoch 134/500\n",
      "124/146 [========================>.....] - ETA: 0s - loss: 8373.4424 - mean_absolute_error: 8373.4424\n",
      "Epoch 134: mean_absolute_error did not improve from 7701.21338\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 8354.1631 - mean_absolute_error: 8354.1631 - val_loss: 7061.1768 - val_mean_absolute_error: 7061.1768\n",
      "Epoch 135/500\n",
      "128/146 [=========================>....] - ETA: 0s - loss: 7883.2515 - mean_absolute_error: 7883.2515\n",
      "Epoch 135: mean_absolute_error did not improve from 7701.21338\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7865.7173 - mean_absolute_error: 7865.7173 - val_loss: 6983.0142 - val_mean_absolute_error: 6983.0142\n",
      "Epoch 136/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 7623.0405 - mean_absolute_error: 7623.0405\n",
      "Epoch 136: mean_absolute_error improved from 7701.21338 to 7620.27148, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7620.2715 - mean_absolute_error: 7620.2715 - val_loss: 6743.7471 - val_mean_absolute_error: 6743.7471\n",
      "Epoch 137/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 7782.4624 - mean_absolute_error: 7782.4624\n",
      "Epoch 137: mean_absolute_error did not improve from 7620.27148\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7758.6548 - mean_absolute_error: 7758.6548 - val_loss: 6906.1528 - val_mean_absolute_error: 6906.1528\n",
      "Epoch 138/500\n",
      "126/146 [========================>.....] - ETA: 0s - loss: 7648.9688 - mean_absolute_error: 7648.9688\n",
      "Epoch 138: mean_absolute_error did not improve from 7620.27148\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7717.9639 - mean_absolute_error: 7717.9639 - val_loss: 6297.6348 - val_mean_absolute_error: 6297.6348\n",
      "Epoch 139/500\n",
      "144/146 [============================>.] - ETA: 0s - loss: 7404.6353 - mean_absolute_error: 7404.6353\n",
      "Epoch 139: mean_absolute_error improved from 7620.27148 to 7429.56885, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7429.5688 - mean_absolute_error: 7429.5688 - val_loss: 6287.0947 - val_mean_absolute_error: 6287.0947\n",
      "Epoch 140/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7596.2173 - mean_absolute_error: 7596.2173\n",
      "Epoch 140: mean_absolute_error did not improve from 7429.56885\n",
      "146/146 [==============================] - 1s 3ms/step - loss: 7587.5723 - mean_absolute_error: 7587.5723 - val_loss: 6385.5586 - val_mean_absolute_error: 6385.5586\n",
      "Epoch 141/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 7526.6030 - mean_absolute_error: 7526.6030\n",
      "Epoch 141: mean_absolute_error did not improve from 7429.56885\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7525.7539 - mean_absolute_error: 7525.7539 - val_loss: 6585.3228 - val_mean_absolute_error: 6585.3228\n",
      "Epoch 142/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 7489.4976 - mean_absolute_error: 7489.4976\n",
      "Epoch 142: mean_absolute_error did not improve from 7429.56885\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7483.7070 - mean_absolute_error: 7483.7070 - val_loss: 6529.0791 - val_mean_absolute_error: 6529.0791\n",
      "Epoch 143/500\n",
      "141/146 [===========================>..] - ETA: 0s - loss: 7371.4565 - mean_absolute_error: 7371.4565\n",
      "Epoch 143: mean_absolute_error improved from 7429.56885 to 7411.36865, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7411.3687 - mean_absolute_error: 7411.3687 - val_loss: 6429.0718 - val_mean_absolute_error: 6429.0718\n",
      "Epoch 144/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 7722.5454 - mean_absolute_error: 7722.5454\n",
      "Epoch 144: mean_absolute_error did not improve from 7411.36865\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7701.0513 - mean_absolute_error: 7701.0513 - val_loss: 6432.2417 - val_mean_absolute_error: 6432.2417\n",
      "Epoch 145/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7427.0571 - mean_absolute_error: 7427.0571\n",
      "Epoch 145: mean_absolute_error did not improve from 7411.36865\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7552.2642 - mean_absolute_error: 7552.2642 - val_loss: 6432.9268 - val_mean_absolute_error: 6432.9268\n",
      "Epoch 146/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7524.3804 - mean_absolute_error: 7524.3804\n",
      "Epoch 146: mean_absolute_error did not improve from 7411.36865\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7526.4062 - mean_absolute_error: 7526.4062 - val_loss: 6285.9731 - val_mean_absolute_error: 6285.9731\n",
      "Epoch 147/500\n",
      "131/146 [=========================>....] - ETA: 0s - loss: 7363.1821 - mean_absolute_error: 7363.1821\n",
      "Epoch 147: mean_absolute_error improved from 7411.36865 to 7411.25000, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7411.2500 - mean_absolute_error: 7411.2500 - val_loss: 6361.2925 - val_mean_absolute_error: 6361.2925\n",
      "Epoch 148/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 7555.9395 - mean_absolute_error: 7555.9395\n",
      "Epoch 148: mean_absolute_error did not improve from 7411.25000\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7548.1592 - mean_absolute_error: 7548.1592 - val_loss: 6278.3271 - val_mean_absolute_error: 6278.3271\n",
      "Epoch 149/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 7454.4736 - mean_absolute_error: 7454.4736\n",
      "Epoch 149: mean_absolute_error did not improve from 7411.25000\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7468.3516 - mean_absolute_error: 7468.3516 - val_loss: 6538.5571 - val_mean_absolute_error: 6538.5571\n",
      "Epoch 150/500\n",
      "128/146 [=========================>....] - ETA: 0s - loss: 7477.9043 - mean_absolute_error: 7477.9043\n",
      "Epoch 150: mean_absolute_error did not improve from 7411.25000\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7482.2725 - mean_absolute_error: 7482.2725 - val_loss: 6228.7891 - val_mean_absolute_error: 6228.7891\n",
      "Epoch 151/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 7360.1064 - mean_absolute_error: 7360.1064\n",
      "Epoch 151: mean_absolute_error improved from 7411.25000 to 7386.51172, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7386.5117 - mean_absolute_error: 7386.5117 - val_loss: 6268.9595 - val_mean_absolute_error: 6268.9595\n",
      "Epoch 152/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7477.0728 - mean_absolute_error: 7477.0728\n",
      "Epoch 152: mean_absolute_error did not improve from 7386.51172\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7472.9478 - mean_absolute_error: 7472.9478 - val_loss: 6282.7769 - val_mean_absolute_error: 6282.7769\n",
      "Epoch 153/500\n",
      "146/146 [==============================] - ETA: 0s - loss: 7502.1621 - mean_absolute_error: 7502.1621\n",
      "Epoch 153: mean_absolute_error did not improve from 7386.51172\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7502.1621 - mean_absolute_error: 7502.1621 - val_loss: 6252.6499 - val_mean_absolute_error: 6252.6499\n",
      "Epoch 154/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 7417.2490 - mean_absolute_error: 7417.2490\n",
      "Epoch 154: mean_absolute_error did not improve from 7386.51172\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7423.9561 - mean_absolute_error: 7423.9561 - val_loss: 6304.9312 - val_mean_absolute_error: 6304.9312\n",
      "Epoch 155/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 7415.4683 - mean_absolute_error: 7415.4683\n",
      "Epoch 155: mean_absolute_error did not improve from 7386.51172\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7394.7300 - mean_absolute_error: 7394.7300 - val_loss: 6354.4971 - val_mean_absolute_error: 6354.4971\n",
      "Epoch 156/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 7342.0586 - mean_absolute_error: 7342.0586\n",
      "Epoch 156: mean_absolute_error improved from 7386.51172 to 7384.33252, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 1s 3ms/step - loss: 7384.3325 - mean_absolute_error: 7384.3325 - val_loss: 6220.1675 - val_mean_absolute_error: 6220.1675\n",
      "Epoch 157/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 7350.7266 - mean_absolute_error: 7350.7266\n",
      "Epoch 157: mean_absolute_error improved from 7384.33252 to 7351.26318, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7351.2632 - mean_absolute_error: 7351.2632 - val_loss: 6320.2241 - val_mean_absolute_error: 6320.2241\n",
      "Epoch 158/500\n",
      "126/146 [========================>.....] - ETA: 0s - loss: 7609.6235 - mean_absolute_error: 7609.6235\n",
      "Epoch 158: mean_absolute_error did not improve from 7351.26318\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7590.6831 - mean_absolute_error: 7590.6831 - val_loss: 6250.7563 - val_mean_absolute_error: 6250.7563\n",
      "Epoch 159/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7472.9229 - mean_absolute_error: 7472.9229\n",
      "Epoch 159: mean_absolute_error did not improve from 7351.26318\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7487.7358 - mean_absolute_error: 7487.7358 - val_loss: 6272.2090 - val_mean_absolute_error: 6272.2090\n",
      "Epoch 160/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 7433.8276 - mean_absolute_error: 7433.8276\n",
      "Epoch 160: mean_absolute_error did not improve from 7351.26318\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7417.5791 - mean_absolute_error: 7417.5791 - val_loss: 6242.3403 - val_mean_absolute_error: 6242.3403\n",
      "Epoch 161/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7331.2124 - mean_absolute_error: 7331.2124\n",
      "Epoch 161: mean_absolute_error improved from 7351.26318 to 7319.85156, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7319.8516 - mean_absolute_error: 7319.8516 - val_loss: 6244.3735 - val_mean_absolute_error: 6244.3735\n",
      "Epoch 162/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 7410.4761 - mean_absolute_error: 7410.4761\n",
      "Epoch 162: mean_absolute_error did not improve from 7319.85156\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7441.5723 - mean_absolute_error: 7441.5723 - val_loss: 6329.5820 - val_mean_absolute_error: 6329.5820\n",
      "Epoch 163/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 7388.1885 - mean_absolute_error: 7388.1885\n",
      "Epoch 163: mean_absolute_error did not improve from 7319.85156\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7376.0190 - mean_absolute_error: 7376.0190 - val_loss: 6237.5396 - val_mean_absolute_error: 6237.5396\n",
      "Epoch 164/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 7341.1265 - mean_absolute_error: 7341.1265\n",
      "Epoch 164: mean_absolute_error did not improve from 7319.85156\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7353.0034 - mean_absolute_error: 7353.0034 - val_loss: 6228.1382 - val_mean_absolute_error: 6228.1382\n",
      "Epoch 165/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 7394.9146 - mean_absolute_error: 7394.9146\n",
      "Epoch 165: mean_absolute_error did not improve from 7319.85156\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7429.4053 - mean_absolute_error: 7429.4053 - val_loss: 6332.3647 - val_mean_absolute_error: 6332.3647\n",
      "Epoch 166/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 7423.9819 - mean_absolute_error: 7423.9819\n",
      "Epoch 166: mean_absolute_error did not improve from 7319.85156\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7410.2964 - mean_absolute_error: 7410.2964 - val_loss: 6234.6641 - val_mean_absolute_error: 6234.6641\n",
      "Epoch 167/500\n",
      "145/146 [============================>.] - ETA: 0s - loss: 7338.1904 - mean_absolute_error: 7338.1904\n",
      "Epoch 167: mean_absolute_error did not improve from 7319.85156\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7340.0332 - mean_absolute_error: 7340.0332 - val_loss: 6226.6777 - val_mean_absolute_error: 6226.6777\n",
      "Epoch 168/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 7238.0474 - mean_absolute_error: 7238.0474\n",
      "Epoch 168: mean_absolute_error improved from 7319.85156 to 7260.93652, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7260.9365 - mean_absolute_error: 7260.9365 - val_loss: 6231.0669 - val_mean_absolute_error: 6231.0669\n",
      "Epoch 169/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 7387.6733 - mean_absolute_error: 7387.6733\n",
      "Epoch 169: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7388.5234 - mean_absolute_error: 7388.5234 - val_loss: 6223.9956 - val_mean_absolute_error: 6223.9956\n",
      "Epoch 170/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 7332.0566 - mean_absolute_error: 7332.0566\n",
      "Epoch 170: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7367.8174 - mean_absolute_error: 7367.8174 - val_loss: 6235.2285 - val_mean_absolute_error: 6235.2285\n",
      "Epoch 171/500\n",
      "145/146 [============================>.] - ETA: 0s - loss: 7329.7163 - mean_absolute_error: 7329.7163\n",
      "Epoch 171: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7338.8579 - mean_absolute_error: 7338.8579 - val_loss: 6214.2402 - val_mean_absolute_error: 6214.2402\n",
      "Epoch 172/500\n",
      "131/146 [=========================>....] - ETA: 0s - loss: 7323.7368 - mean_absolute_error: 7323.7368\n",
      "Epoch 172: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7298.3667 - mean_absolute_error: 7298.3667 - val_loss: 6214.0024 - val_mean_absolute_error: 6214.0024\n",
      "Epoch 173/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 7385.8604 - mean_absolute_error: 7385.8604\n",
      "Epoch 173: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7345.8853 - mean_absolute_error: 7345.8853 - val_loss: 6229.4878 - val_mean_absolute_error: 6229.4878\n",
      "Epoch 174/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 7411.4829 - mean_absolute_error: 7411.4829\n",
      "Epoch 174: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7362.0967 - mean_absolute_error: 7362.0967 - val_loss: 6220.2402 - val_mean_absolute_error: 6220.2402\n",
      "Epoch 175/500\n",
      "141/146 [===========================>..] - ETA: 0s - loss: 7430.6362 - mean_absolute_error: 7430.6362\n",
      "Epoch 175: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7416.1328 - mean_absolute_error: 7416.1328 - val_loss: 6265.1245 - val_mean_absolute_error: 6265.1245\n",
      "Epoch 176/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 7348.8789 - mean_absolute_error: 7348.8789\n",
      "Epoch 176: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 7360.5820 - mean_absolute_error: 7360.5820 - val_loss: 6214.9658 - val_mean_absolute_error: 6214.9658\n",
      "Epoch 177/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 7326.2515 - mean_absolute_error: 7326.2515\n",
      "Epoch 177: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7316.8252 - mean_absolute_error: 7316.8252 - val_loss: 6242.0576 - val_mean_absolute_error: 6242.0576\n",
      "Epoch 178/500\n",
      "131/146 [=========================>....] - ETA: 0s - loss: 7490.8955 - mean_absolute_error: 7490.8955\n",
      "Epoch 178: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7466.8481 - mean_absolute_error: 7466.8481 - val_loss: 6233.7656 - val_mean_absolute_error: 6233.7656\n",
      "Epoch 179/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 7393.3076 - mean_absolute_error: 7393.3076\n",
      "Epoch 179: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7409.7676 - mean_absolute_error: 7409.7676 - val_loss: 6278.2256 - val_mean_absolute_error: 6278.2256\n",
      "Epoch 180/500\n",
      "146/146 [==============================] - ETA: 0s - loss: 7553.6460 - mean_absolute_error: 7553.6460\n",
      "Epoch 180: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7553.6460 - mean_absolute_error: 7553.6460 - val_loss: 6243.5303 - val_mean_absolute_error: 6243.5303\n",
      "Epoch 181/500\n",
      "126/146 [========================>.....] - ETA: 0s - loss: 7346.5918 - mean_absolute_error: 7346.5918\n",
      "Epoch 181: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7337.4902 - mean_absolute_error: 7337.4902 - val_loss: 6308.7734 - val_mean_absolute_error: 6308.7734\n",
      "Epoch 182/500\n",
      "126/146 [========================>.....] - ETA: 0s - loss: 7227.3535 - mean_absolute_error: 7227.3535\n",
      "Epoch 182: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7286.1240 - mean_absolute_error: 7286.1240 - val_loss: 6217.3481 - val_mean_absolute_error: 6217.3481\n",
      "Epoch 183/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 7301.5664 - mean_absolute_error: 7301.5664\n",
      "Epoch 183: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7308.7925 - mean_absolute_error: 7308.7925 - val_loss: 6226.3984 - val_mean_absolute_error: 6226.3984\n",
      "Epoch 184/500\n",
      "146/146 [==============================] - ETA: 0s - loss: 7354.7310 - mean_absolute_error: 7354.7310\n",
      "Epoch 184: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7354.7310 - mean_absolute_error: 7354.7310 - val_loss: 6288.5054 - val_mean_absolute_error: 6288.5054\n",
      "Epoch 185/500\n",
      "136/146 [==========================>...] - ETA: 0s - loss: 7414.6211 - mean_absolute_error: 7414.6211\n",
      "Epoch 185: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7419.7446 - mean_absolute_error: 7419.7446 - val_loss: 6220.6543 - val_mean_absolute_error: 6220.6543\n",
      "Epoch 186/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 7316.8193 - mean_absolute_error: 7316.8193\n",
      "Epoch 186: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7332.3813 - mean_absolute_error: 7332.3813 - val_loss: 6214.7378 - val_mean_absolute_error: 6214.7378\n",
      "Epoch 187/500\n",
      "124/146 [========================>.....] - ETA: 0s - loss: 7506.6284 - mean_absolute_error: 7506.6284\n",
      "Epoch 187: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7381.2100 - mean_absolute_error: 7381.2100 - val_loss: 6222.0718 - val_mean_absolute_error: 6222.0718\n",
      "Epoch 188/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 7411.7070 - mean_absolute_error: 7411.7070\n",
      "Epoch 188: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7422.2314 - mean_absolute_error: 7422.2314 - val_loss: 6214.6816 - val_mean_absolute_error: 6214.6816\n",
      "Epoch 189/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 7278.6382 - mean_absolute_error: 7278.6382\n",
      "Epoch 189: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7329.9272 - mean_absolute_error: 7329.9272 - val_loss: 6233.0396 - val_mean_absolute_error: 6233.0396\n",
      "Epoch 190/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 7469.1587 - mean_absolute_error: 7469.1587\n",
      "Epoch 190: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7454.6108 - mean_absolute_error: 7454.6108 - val_loss: 6264.6079 - val_mean_absolute_error: 6264.6079\n",
      "Epoch 191/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 7478.2510 - mean_absolute_error: 7478.2510\n",
      "Epoch 191: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7467.9219 - mean_absolute_error: 7467.9219 - val_loss: 6214.7949 - val_mean_absolute_error: 6214.7949\n",
      "Epoch 192/500\n",
      "145/146 [============================>.] - ETA: 0s - loss: 7320.2036 - mean_absolute_error: 7320.2036\n",
      "Epoch 192: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7335.1611 - mean_absolute_error: 7335.1611 - val_loss: 6227.6875 - val_mean_absolute_error: 6227.6875\n",
      "Epoch 193/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 7334.6968 - mean_absolute_error: 7334.6968\n",
      "Epoch 193: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7312.7856 - mean_absolute_error: 7312.7856 - val_loss: 6290.2104 - val_mean_absolute_error: 6290.2104\n",
      "Epoch 194/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 7372.9780 - mean_absolute_error: 7372.9780\n",
      "Epoch 194: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7363.2769 - mean_absolute_error: 7363.2769 - val_loss: 6228.1870 - val_mean_absolute_error: 6228.1870\n",
      "Epoch 195/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 7349.7944 - mean_absolute_error: 7349.7944\n",
      "Epoch 195: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7359.3267 - mean_absolute_error: 7359.3267 - val_loss: 6215.5718 - val_mean_absolute_error: 6215.5718\n",
      "Epoch 196/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 7339.6245 - mean_absolute_error: 7339.6245\n",
      "Epoch 196: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7380.6797 - mean_absolute_error: 7380.6797 - val_loss: 6453.3037 - val_mean_absolute_error: 6453.3037\n",
      "Epoch 197/500\n",
      "136/146 [==========================>...] - ETA: 0s - loss: 7352.5947 - mean_absolute_error: 7352.5947\n",
      "Epoch 197: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7331.4893 - mean_absolute_error: 7331.4893 - val_loss: 6214.4976 - val_mean_absolute_error: 6214.4976\n",
      "Epoch 198/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 7317.1499 - mean_absolute_error: 7317.1499\n",
      "Epoch 198: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7295.6240 - mean_absolute_error: 7295.6240 - val_loss: 6289.0322 - val_mean_absolute_error: 6289.0322\n",
      "Epoch 199/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 7278.3218 - mean_absolute_error: 7278.3218\n",
      "Epoch 199: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7291.7607 - mean_absolute_error: 7291.7607 - val_loss: 6216.5293 - val_mean_absolute_error: 6216.5293\n",
      "Epoch 200/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 7308.3760 - mean_absolute_error: 7308.3760\n",
      "Epoch 200: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7290.9355 - mean_absolute_error: 7290.9355 - val_loss: 6235.6328 - val_mean_absolute_error: 6235.6328\n",
      "Epoch 201/500\n",
      "136/146 [==========================>...] - ETA: 0s - loss: 7378.9805 - mean_absolute_error: 7378.9805\n",
      "Epoch 201: mean_absolute_error did not improve from 7260.93652\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7399.8862 - mean_absolute_error: 7399.8862 - val_loss: 6231.4189 - val_mean_absolute_error: 6231.4189\n",
      "Epoch 202/500\n",
      "145/146 [============================>.] - ETA: 0s - loss: 7238.7510 - mean_absolute_error: 7238.7510\n",
      "Epoch 202: mean_absolute_error improved from 7260.93652 to 7233.94238, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7233.9424 - mean_absolute_error: 7233.9424 - val_loss: 6219.9805 - val_mean_absolute_error: 6219.9805\n",
      "Epoch 203/500\n",
      "146/146 [==============================] - ETA: 0s - loss: 7304.7539 - mean_absolute_error: 7304.7539\n",
      "Epoch 203: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7304.7539 - mean_absolute_error: 7304.7539 - val_loss: 6215.4858 - val_mean_absolute_error: 6215.4858\n",
      "Epoch 204/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 7432.5801 - mean_absolute_error: 7432.5801\n",
      "Epoch 204: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7397.8442 - mean_absolute_error: 7397.8442 - val_loss: 6318.4106 - val_mean_absolute_error: 6318.4106\n",
      "Epoch 205/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 7318.7480 - mean_absolute_error: 7318.7480\n",
      "Epoch 205: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7358.2861 - mean_absolute_error: 7358.2861 - val_loss: 6278.5781 - val_mean_absolute_error: 6278.5781\n",
      "Epoch 206/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 7333.1025 - mean_absolute_error: 7333.1025\n",
      "Epoch 206: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7285.9282 - mean_absolute_error: 7285.9282 - val_loss: 6273.4561 - val_mean_absolute_error: 6273.4561\n",
      "Epoch 207/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7204.1206 - mean_absolute_error: 7204.1206\n",
      "Epoch 207: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7250.6548 - mean_absolute_error: 7250.6548 - val_loss: 6231.5962 - val_mean_absolute_error: 6231.5962\n",
      "Epoch 208/500\n",
      "126/146 [========================>.....] - ETA: 0s - loss: 7232.4648 - mean_absolute_error: 7232.4648\n",
      "Epoch 208: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7271.0112 - mean_absolute_error: 7271.0112 - val_loss: 6215.4580 - val_mean_absolute_error: 6215.4580\n",
      "Epoch 209/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 7318.5674 - mean_absolute_error: 7318.5674\n",
      "Epoch 209: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7343.6108 - mean_absolute_error: 7343.6108 - val_loss: 6237.5303 - val_mean_absolute_error: 6237.5303\n",
      "Epoch 210/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 7313.3857 - mean_absolute_error: 7313.3857\n",
      "Epoch 210: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7339.5439 - mean_absolute_error: 7339.5439 - val_loss: 6217.8076 - val_mean_absolute_error: 6217.8076\n",
      "Epoch 211/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 7391.0049 - mean_absolute_error: 7391.0049\n",
      "Epoch 211: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7319.2920 - mean_absolute_error: 7319.2920 - val_loss: 6234.0669 - val_mean_absolute_error: 6234.0669\n",
      "Epoch 212/500\n",
      "146/146 [==============================] - ETA: 0s - loss: 7322.8618 - mean_absolute_error: 7322.8618\n",
      "Epoch 212: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7322.8618 - mean_absolute_error: 7322.8618 - val_loss: 6260.8931 - val_mean_absolute_error: 6260.8931\n",
      "Epoch 213/500\n",
      "126/146 [========================>.....] - ETA: 0s - loss: 7389.3276 - mean_absolute_error: 7389.3276\n",
      "Epoch 213: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7304.3076 - mean_absolute_error: 7304.3076 - val_loss: 6221.9839 - val_mean_absolute_error: 6221.9839\n",
      "Epoch 214/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7432.5840 - mean_absolute_error: 7432.5840\n",
      "Epoch 214: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7431.7148 - mean_absolute_error: 7431.7148 - val_loss: 6287.3491 - val_mean_absolute_error: 6287.3491\n",
      "Epoch 215/500\n",
      "117/146 [=======================>......] - ETA: 0s - loss: 7292.8799 - mean_absolute_error: 7292.8799\n",
      "Epoch 215: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7332.4268 - mean_absolute_error: 7332.4268 - val_loss: 6237.7163 - val_mean_absolute_error: 6237.7163\n",
      "Epoch 216/500\n",
      "126/146 [========================>.....] - ETA: 0s - loss: 7461.0444 - mean_absolute_error: 7461.0444\n",
      "Epoch 216: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7417.5244 - mean_absolute_error: 7417.5244 - val_loss: 6448.4648 - val_mean_absolute_error: 6448.4648\n",
      "Epoch 217/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 7336.7812 - mean_absolute_error: 7336.7812\n",
      "Epoch 217: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7325.0977 - mean_absolute_error: 7325.0977 - val_loss: 6280.2173 - val_mean_absolute_error: 6280.2173\n",
      "Epoch 218/500\n",
      "131/146 [=========================>....] - ETA: 0s - loss: 7336.0698 - mean_absolute_error: 7336.0698\n",
      "Epoch 218: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7337.9287 - mean_absolute_error: 7337.9287 - val_loss: 6220.1201 - val_mean_absolute_error: 6220.1201\n",
      "Epoch 219/500\n",
      "131/146 [=========================>....] - ETA: 0s - loss: 7307.5000 - mean_absolute_error: 7307.5000\n",
      "Epoch 219: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7317.8296 - mean_absolute_error: 7317.8296 - val_loss: 6223.1885 - val_mean_absolute_error: 6223.1885\n",
      "Epoch 220/500\n",
      "145/146 [============================>.] - ETA: 0s - loss: 7434.0405 - mean_absolute_error: 7434.0405\n",
      "Epoch 220: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7443.7334 - mean_absolute_error: 7443.7334 - val_loss: 6264.7476 - val_mean_absolute_error: 6264.7476\n",
      "Epoch 221/500\n",
      "136/146 [==========================>...] - ETA: 0s - loss: 7399.7974 - mean_absolute_error: 7399.7974\n",
      "Epoch 221: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7372.2759 - mean_absolute_error: 7372.2759 - val_loss: 6219.8374 - val_mean_absolute_error: 6219.8374\n",
      "Epoch 222/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 7305.4771 - mean_absolute_error: 7305.4771\n",
      "Epoch 222: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7310.9272 - mean_absolute_error: 7310.9272 - val_loss: 6236.7183 - val_mean_absolute_error: 6236.7183\n",
      "Epoch 223/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7299.2744 - mean_absolute_error: 7299.2744\n",
      "Epoch 223: mean_absolute_error did not improve from 7233.94238\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7312.7002 - mean_absolute_error: 7312.7002 - val_loss: 6231.5854 - val_mean_absolute_error: 6231.5854\n",
      "Epoch 224/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 7212.8623 - mean_absolute_error: 7212.8623\n",
      "Epoch 224: mean_absolute_error improved from 7233.94238 to 7226.59033, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7226.5903 - mean_absolute_error: 7226.5903 - val_loss: 6219.1670 - val_mean_absolute_error: 6219.1670\n",
      "Epoch 225/500\n",
      "123/146 [========================>.....] - ETA: 0s - loss: 7330.5850 - mean_absolute_error: 7330.5850\n",
      "Epoch 225: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7343.7812 - mean_absolute_error: 7343.7812 - val_loss: 6270.3223 - val_mean_absolute_error: 6270.3223\n",
      "Epoch 226/500\n",
      "126/146 [========================>.....] - ETA: 0s - loss: 7412.8672 - mean_absolute_error: 7412.8672\n",
      "Epoch 226: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7399.7910 - mean_absolute_error: 7399.7910 - val_loss: 6230.0957 - val_mean_absolute_error: 6230.0957\n",
      "Epoch 227/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 7262.5859 - mean_absolute_error: 7262.5859\n",
      "Epoch 227: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7263.2656 - mean_absolute_error: 7263.2656 - val_loss: 6284.0488 - val_mean_absolute_error: 6284.0488\n",
      "Epoch 228/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7467.5439 - mean_absolute_error: 7467.5439\n",
      "Epoch 228: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7453.7832 - mean_absolute_error: 7453.7832 - val_loss: 6221.8198 - val_mean_absolute_error: 6221.8198\n",
      "Epoch 229/500\n",
      "118/146 [=======================>......] - ETA: 0s - loss: 7286.0000 - mean_absolute_error: 7286.0000\n",
      "Epoch 229: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7321.9058 - mean_absolute_error: 7321.9058 - val_loss: 6286.8022 - val_mean_absolute_error: 6286.8022\n",
      "Epoch 230/500\n",
      "145/146 [============================>.] - ETA: 0s - loss: 7270.3467 - mean_absolute_error: 7270.3467\n",
      "Epoch 230: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7264.9839 - mean_absolute_error: 7264.9839 - val_loss: 6228.4961 - val_mean_absolute_error: 6228.4961\n",
      "Epoch 231/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 7440.9526 - mean_absolute_error: 7440.9526\n",
      "Epoch 231: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7407.7773 - mean_absolute_error: 7407.7773 - val_loss: 6214.2969 - val_mean_absolute_error: 6214.2969\n",
      "Epoch 232/500\n",
      "123/146 [========================>.....] - ETA: 0s - loss: 7359.2153 - mean_absolute_error: 7359.2153\n",
      "Epoch 232: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7301.2529 - mean_absolute_error: 7301.2529 - val_loss: 6237.9810 - val_mean_absolute_error: 6237.9810\n",
      "Epoch 233/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 7429.4971 - mean_absolute_error: 7429.4971\n",
      "Epoch 233: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7378.0034 - mean_absolute_error: 7378.0034 - val_loss: 6218.2603 - val_mean_absolute_error: 6218.2603\n",
      "Epoch 234/500\n",
      "123/146 [========================>.....] - ETA: 0s - loss: 7380.1772 - mean_absolute_error: 7380.1772\n",
      "Epoch 234: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7381.8159 - mean_absolute_error: 7381.8159 - val_loss: 6218.1855 - val_mean_absolute_error: 6218.1855\n",
      "Epoch 235/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 7298.6943 - mean_absolute_error: 7298.6943\n",
      "Epoch 235: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7278.9253 - mean_absolute_error: 7278.9253 - val_loss: 6240.5503 - val_mean_absolute_error: 6240.5503\n",
      "Epoch 236/500\n",
      "121/146 [=======================>......] - ETA: 0s - loss: 7304.1504 - mean_absolute_error: 7304.1504\n",
      "Epoch 236: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7327.3403 - mean_absolute_error: 7327.3403 - val_loss: 6318.5176 - val_mean_absolute_error: 6318.5176\n",
      "Epoch 237/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 7266.2812 - mean_absolute_error: 7266.2812\n",
      "Epoch 237: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7282.0259 - mean_absolute_error: 7282.0259 - val_loss: 6324.8013 - val_mean_absolute_error: 6324.8013\n",
      "Epoch 238/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 7239.6772 - mean_absolute_error: 7239.6772\n",
      "Epoch 238: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7241.5767 - mean_absolute_error: 7241.5767 - val_loss: 6232.1997 - val_mean_absolute_error: 6232.1997\n",
      "Epoch 239/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7289.5103 - mean_absolute_error: 7289.5103\n",
      "Epoch 239: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7295.5962 - mean_absolute_error: 7295.5962 - val_loss: 6252.5239 - val_mean_absolute_error: 6252.5239\n",
      "Epoch 240/500\n",
      "120/146 [=======================>......] - ETA: 0s - loss: 7371.7207 - mean_absolute_error: 7371.7207\n",
      "Epoch 240: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7307.5537 - mean_absolute_error: 7307.5537 - val_loss: 6299.1094 - val_mean_absolute_error: 6299.1094\n",
      "Epoch 241/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 7497.0610 - mean_absolute_error: 7497.0610\n",
      "Epoch 241: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7478.7979 - mean_absolute_error: 7478.7979 - val_loss: 6345.6729 - val_mean_absolute_error: 6345.6729\n",
      "Epoch 242/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7437.0610 - mean_absolute_error: 7437.0610\n",
      "Epoch 242: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7375.2358 - mean_absolute_error: 7375.2358 - val_loss: 6221.5962 - val_mean_absolute_error: 6221.5962\n",
      "Epoch 243/500\n",
      "131/146 [=========================>....] - ETA: 0s - loss: 7363.8394 - mean_absolute_error: 7363.8394\n",
      "Epoch 243: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7341.2598 - mean_absolute_error: 7341.2598 - val_loss: 6269.3604 - val_mean_absolute_error: 6269.3604\n",
      "Epoch 244/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 7327.2871 - mean_absolute_error: 7327.2871\n",
      "Epoch 244: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7322.0000 - mean_absolute_error: 7322.0000 - val_loss: 6223.9526 - val_mean_absolute_error: 6223.9526\n",
      "Epoch 245/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 7360.3682 - mean_absolute_error: 7360.3682\n",
      "Epoch 245: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7313.9741 - mean_absolute_error: 7313.9741 - val_loss: 6238.9351 - val_mean_absolute_error: 6238.9351\n",
      "Epoch 246/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 7231.0972 - mean_absolute_error: 7231.0972\n",
      "Epoch 246: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7342.8096 - mean_absolute_error: 7342.8096 - val_loss: 6218.6958 - val_mean_absolute_error: 6218.6958\n",
      "Epoch 247/500\n",
      "122/146 [========================>.....] - ETA: 0s - loss: 7470.0552 - mean_absolute_error: 7470.0552\n",
      "Epoch 247: mean_absolute_error did not improve from 7226.59033\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7329.3530 - mean_absolute_error: 7329.3530 - val_loss: 6216.7480 - val_mean_absolute_error: 6216.7480\n",
      "Epoch 248/500\n",
      "131/146 [=========================>....] - ETA: 0s - loss: 7257.3994 - mean_absolute_error: 7257.3994\n",
      "Epoch 248: mean_absolute_error improved from 7226.59033 to 7223.86035, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7223.8604 - mean_absolute_error: 7223.8604 - val_loss: 6242.3384 - val_mean_absolute_error: 6242.3384\n",
      "Epoch 249/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 7231.1084 - mean_absolute_error: 7231.1084\n",
      "Epoch 249: mean_absolute_error did not improve from 7223.86035\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7269.0430 - mean_absolute_error: 7269.0430 - val_loss: 6222.3799 - val_mean_absolute_error: 6222.3799\n",
      "Epoch 250/500\n",
      "143/146 [============================>.] - ETA: 0s - loss: 7309.5640 - mean_absolute_error: 7309.5640\n",
      "Epoch 250: mean_absolute_error did not improve from 7223.86035\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7281.0479 - mean_absolute_error: 7281.0479 - val_loss: 6248.1064 - val_mean_absolute_error: 6248.1064\n",
      "Epoch 251/500\n",
      "131/146 [=========================>....] - ETA: 0s - loss: 7278.6392 - mean_absolute_error: 7278.6392\n",
      "Epoch 251: mean_absolute_error did not improve from 7223.86035\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7293.1636 - mean_absolute_error: 7293.1636 - val_loss: 6270.8413 - val_mean_absolute_error: 6270.8413\n",
      "Epoch 252/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 7201.3804 - mean_absolute_error: 7201.3804\n",
      "Epoch 252: mean_absolute_error improved from 7223.86035 to 7219.80713, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7219.8071 - mean_absolute_error: 7219.8071 - val_loss: 6230.1807 - val_mean_absolute_error: 6230.1807\n",
      "Epoch 253/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 7301.3550 - mean_absolute_error: 7301.3550\n",
      "Epoch 253: mean_absolute_error did not improve from 7219.80713\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7325.6230 - mean_absolute_error: 7325.6230 - val_loss: 6279.6240 - val_mean_absolute_error: 6279.6240\n",
      "Epoch 254/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7413.9492 - mean_absolute_error: 7413.9492\n",
      "Epoch 254: mean_absolute_error did not improve from 7219.80713\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7383.6050 - mean_absolute_error: 7383.6050 - val_loss: 6238.1187 - val_mean_absolute_error: 6238.1187\n",
      "Epoch 255/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7384.1802 - mean_absolute_error: 7384.1802\n",
      "Epoch 255: mean_absolute_error did not improve from 7219.80713\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7352.0576 - mean_absolute_error: 7352.0576 - val_loss: 6218.6079 - val_mean_absolute_error: 6218.6079\n",
      "Epoch 256/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 7243.4834 - mean_absolute_error: 7243.4834\n",
      "Epoch 256: mean_absolute_error did not improve from 7219.80713\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7343.9546 - mean_absolute_error: 7343.9546 - val_loss: 6317.9585 - val_mean_absolute_error: 6317.9585\n",
      "Epoch 257/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 7331.6982 - mean_absolute_error: 7331.6982\n",
      "Epoch 257: mean_absolute_error did not improve from 7219.80713\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7331.3042 - mean_absolute_error: 7331.3042 - val_loss: 6218.5278 - val_mean_absolute_error: 6218.5278\n",
      "Epoch 258/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 7347.4756 - mean_absolute_error: 7347.4756\n",
      "Epoch 258: mean_absolute_error did not improve from 7219.80713\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7348.7573 - mean_absolute_error: 7348.7573 - val_loss: 6281.1274 - val_mean_absolute_error: 6281.1274\n",
      "Epoch 259/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 7323.5308 - mean_absolute_error: 7323.5308\n",
      "Epoch 259: mean_absolute_error did not improve from 7219.80713\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7307.8013 - mean_absolute_error: 7307.8013 - val_loss: 6307.0737 - val_mean_absolute_error: 6307.0737\n",
      "Epoch 260/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7429.3042 - mean_absolute_error: 7429.3042\n",
      "Epoch 260: mean_absolute_error did not improve from 7219.80713\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7397.0581 - mean_absolute_error: 7397.0581 - val_loss: 6261.1929 - val_mean_absolute_error: 6261.1929\n",
      "Epoch 261/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 7199.4170 - mean_absolute_error: 7199.4170\n",
      "Epoch 261: mean_absolute_error did not improve from 7219.80713\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7221.0352 - mean_absolute_error: 7221.0352 - val_loss: 6267.5020 - val_mean_absolute_error: 6267.5020\n",
      "Epoch 262/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 7195.1260 - mean_absolute_error: 7195.1260\n",
      "Epoch 262: mean_absolute_error did not improve from 7219.80713\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7239.5928 - mean_absolute_error: 7239.5928 - val_loss: 6294.8887 - val_mean_absolute_error: 6294.8887\n",
      "Epoch 263/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 7297.4097 - mean_absolute_error: 7297.4097\n",
      "Epoch 263: mean_absolute_error did not improve from 7219.80713\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7281.2393 - mean_absolute_error: 7281.2393 - val_loss: 6233.7949 - val_mean_absolute_error: 6233.7949\n",
      "Epoch 264/500\n",
      "121/146 [=======================>......] - ETA: 0s - loss: 7269.4077 - mean_absolute_error: 7269.4077\n",
      "Epoch 264: mean_absolute_error did not improve from 7219.80713\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7273.7139 - mean_absolute_error: 7273.7139 - val_loss: 6219.0327 - val_mean_absolute_error: 6219.0327\n",
      "Epoch 265/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 7253.5215 - mean_absolute_error: 7253.5215\n",
      "Epoch 265: mean_absolute_error did not improve from 7219.80713\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7253.2852 - mean_absolute_error: 7253.2852 - val_loss: 6306.3633 - val_mean_absolute_error: 6306.3633\n",
      "Epoch 266/500\n",
      "136/146 [==========================>...] - ETA: 0s - loss: 7304.5249 - mean_absolute_error: 7304.5249\n",
      "Epoch 266: mean_absolute_error did not improve from 7219.80713\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7316.9487 - mean_absolute_error: 7316.9487 - val_loss: 6224.5410 - val_mean_absolute_error: 6224.5410\n",
      "Epoch 267/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7336.4570 - mean_absolute_error: 7336.4570\n",
      "Epoch 267: mean_absolute_error did not improve from 7219.80713\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7290.8149 - mean_absolute_error: 7290.8149 - val_loss: 6221.4600 - val_mean_absolute_error: 6221.4600\n",
      "Epoch 268/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 7385.0415 - mean_absolute_error: 7385.0415\n",
      "Epoch 268: mean_absolute_error did not improve from 7219.80713\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7412.4746 - mean_absolute_error: 7412.4746 - val_loss: 6217.4282 - val_mean_absolute_error: 6217.4282\n",
      "Epoch 269/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7320.5894 - mean_absolute_error: 7320.5894\n",
      "Epoch 269: mean_absolute_error did not improve from 7219.80713\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7314.9707 - mean_absolute_error: 7314.9707 - val_loss: 6249.9116 - val_mean_absolute_error: 6249.9116\n",
      "Epoch 270/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 7416.1592 - mean_absolute_error: 7416.1592\n",
      "Epoch 270: mean_absolute_error did not improve from 7219.80713\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7363.3179 - mean_absolute_error: 7363.3179 - val_loss: 6220.4038 - val_mean_absolute_error: 6220.4038\n",
      "Epoch 271/500\n",
      "144/146 [============================>.] - ETA: 0s - loss: 7281.7417 - mean_absolute_error: 7281.7417\n",
      "Epoch 271: mean_absolute_error did not improve from 7219.80713\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7273.3359 - mean_absolute_error: 7273.3359 - val_loss: 6216.7495 - val_mean_absolute_error: 6216.7495\n",
      "Epoch 272/500\n",
      "119/146 [=======================>......] - ETA: 0s - loss: 7293.7764 - mean_absolute_error: 7293.7764\n",
      "Epoch 272: mean_absolute_error did not improve from 7219.80713\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7245.1035 - mean_absolute_error: 7245.1035 - val_loss: 6217.8130 - val_mean_absolute_error: 6217.8130\n",
      "Epoch 273/500\n",
      "116/146 [======================>.......] - ETA: 0s - loss: 7250.9312 - mean_absolute_error: 7250.9312\n",
      "Epoch 273: mean_absolute_error improved from 7219.80713 to 7197.14160, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7197.1416 - mean_absolute_error: 7197.1416 - val_loss: 6261.0156 - val_mean_absolute_error: 6261.0156\n",
      "Epoch 274/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 7312.8589 - mean_absolute_error: 7312.8589\n",
      "Epoch 274: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7349.7061 - mean_absolute_error: 7349.7061 - val_loss: 6217.1577 - val_mean_absolute_error: 6217.1577\n",
      "Epoch 275/500\n",
      "136/146 [==========================>...] - ETA: 0s - loss: 7352.2515 - mean_absolute_error: 7352.2515\n",
      "Epoch 275: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7358.0684 - mean_absolute_error: 7358.0684 - val_loss: 6221.9839 - val_mean_absolute_error: 6221.9839\n",
      "Epoch 276/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 7359.6636 - mean_absolute_error: 7359.6636\n",
      "Epoch 276: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7299.2852 - mean_absolute_error: 7299.2852 - val_loss: 6220.2173 - val_mean_absolute_error: 6220.2173\n",
      "Epoch 277/500\n",
      "124/146 [========================>.....] - ETA: 0s - loss: 7276.6714 - mean_absolute_error: 7276.6714\n",
      "Epoch 277: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7274.5845 - mean_absolute_error: 7274.5845 - val_loss: 6268.8003 - val_mean_absolute_error: 6268.8008\n",
      "Epoch 278/500\n",
      "143/146 [============================>.] - ETA: 0s - loss: 7250.0806 - mean_absolute_error: 7250.0806\n",
      "Epoch 278: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7258.6548 - mean_absolute_error: 7258.6548 - val_loss: 6227.4912 - val_mean_absolute_error: 6227.4912\n",
      "Epoch 279/500\n",
      "143/146 [============================>.] - ETA: 0s - loss: 7287.5776 - mean_absolute_error: 7287.5776\n",
      "Epoch 279: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7300.2690 - mean_absolute_error: 7300.2690 - val_loss: 6272.3052 - val_mean_absolute_error: 6272.3052\n",
      "Epoch 280/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 7242.1514 - mean_absolute_error: 7242.1514\n",
      "Epoch 280: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7283.3813 - mean_absolute_error: 7283.3813 - val_loss: 6222.3188 - val_mean_absolute_error: 6222.3188\n",
      "Epoch 281/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 7188.0156 - mean_absolute_error: 7188.0156\n",
      "Epoch 281: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7198.8799 - mean_absolute_error: 7198.8799 - val_loss: 6214.4688 - val_mean_absolute_error: 6214.4688\n",
      "Epoch 282/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 7303.7280 - mean_absolute_error: 7303.7280\n",
      "Epoch 282: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7299.8433 - mean_absolute_error: 7299.8433 - val_loss: 6221.9390 - val_mean_absolute_error: 6221.9390\n",
      "Epoch 283/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 7235.7344 - mean_absolute_error: 7235.7344\n",
      "Epoch 283: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7263.4180 - mean_absolute_error: 7263.4180 - val_loss: 6236.9912 - val_mean_absolute_error: 6236.9912\n",
      "Epoch 284/500\n",
      "131/146 [=========================>....] - ETA: 0s - loss: 7242.0942 - mean_absolute_error: 7242.0942\n",
      "Epoch 284: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7243.7661 - mean_absolute_error: 7243.7661 - val_loss: 6264.8008 - val_mean_absolute_error: 6264.8008\n",
      "Epoch 285/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 7286.8462 - mean_absolute_error: 7286.8462\n",
      "Epoch 285: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7330.8477 - mean_absolute_error: 7330.8477 - val_loss: 6215.5469 - val_mean_absolute_error: 6215.5469\n",
      "Epoch 286/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 7299.8975 - mean_absolute_error: 7299.8975\n",
      "Epoch 286: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7290.0815 - mean_absolute_error: 7290.0815 - val_loss: 6293.3994 - val_mean_absolute_error: 6293.3994\n",
      "Epoch 287/500\n",
      "144/146 [============================>.] - ETA: 0s - loss: 7330.5469 - mean_absolute_error: 7330.5469\n",
      "Epoch 287: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7334.2681 - mean_absolute_error: 7334.2681 - val_loss: 6218.2144 - val_mean_absolute_error: 6218.2144\n",
      "Epoch 288/500\n",
      "126/146 [========================>.....] - ETA: 0s - loss: 7317.1567 - mean_absolute_error: 7317.1567\n",
      "Epoch 288: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7273.4541 - mean_absolute_error: 7273.4541 - val_loss: 6230.3340 - val_mean_absolute_error: 6230.3340\n",
      "Epoch 289/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7235.0532 - mean_absolute_error: 7235.0532\n",
      "Epoch 289: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7281.2568 - mean_absolute_error: 7281.2568 - val_loss: 6225.0884 - val_mean_absolute_error: 6225.0884\n",
      "Epoch 290/500\n",
      "128/146 [=========================>....] - ETA: 0s - loss: 7325.9360 - mean_absolute_error: 7325.9360\n",
      "Epoch 290: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7330.6616 - mean_absolute_error: 7330.6616 - val_loss: 6257.9385 - val_mean_absolute_error: 6257.9385\n",
      "Epoch 291/500\n",
      "145/146 [============================>.] - ETA: 0s - loss: 7275.9346 - mean_absolute_error: 7275.9346\n",
      "Epoch 291: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7278.2202 - mean_absolute_error: 7278.2202 - val_loss: 6218.5029 - val_mean_absolute_error: 6218.5029\n",
      "Epoch 292/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 7324.3916 - mean_absolute_error: 7324.3916\n",
      "Epoch 292: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7332.5356 - mean_absolute_error: 7332.5356 - val_loss: 6260.2842 - val_mean_absolute_error: 6260.2842\n",
      "Epoch 293/500\n",
      "145/146 [============================>.] - ETA: 0s - loss: 7319.3921 - mean_absolute_error: 7319.3921\n",
      "Epoch 293: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7319.8022 - mean_absolute_error: 7319.8022 - val_loss: 6240.1270 - val_mean_absolute_error: 6240.1270\n",
      "Epoch 294/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 7264.2749 - mean_absolute_error: 7264.2749\n",
      "Epoch 294: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7306.7466 - mean_absolute_error: 7306.7466 - val_loss: 6240.2764 - val_mean_absolute_error: 6240.2764\n",
      "Epoch 295/500\n",
      "126/146 [========================>.....] - ETA: 0s - loss: 7585.3867 - mean_absolute_error: 7585.3867\n",
      "Epoch 295: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7529.4424 - mean_absolute_error: 7529.4424 - val_loss: 6218.4868 - val_mean_absolute_error: 6218.4868\n",
      "Epoch 296/500\n",
      "128/146 [=========================>....] - ETA: 0s - loss: 7296.3857 - mean_absolute_error: 7296.3857\n",
      "Epoch 296: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7279.0059 - mean_absolute_error: 7279.0059 - val_loss: 6236.4819 - val_mean_absolute_error: 6236.4819\n",
      "Epoch 297/500\n",
      "144/146 [============================>.] - ETA: 0s - loss: 7220.3291 - mean_absolute_error: 7220.3291\n",
      "Epoch 297: mean_absolute_error did not improve from 7197.14160\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7223.0850 - mean_absolute_error: 7223.0850 - val_loss: 6226.6978 - val_mean_absolute_error: 6226.6978\n",
      "Epoch 298/500\n",
      "145/146 [============================>.] - ETA: 0s - loss: 7193.8291 - mean_absolute_error: 7193.8291\n",
      "Epoch 298: mean_absolute_error improved from 7197.14160 to 7188.91064, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7188.9106 - mean_absolute_error: 7188.9106 - val_loss: 6236.1973 - val_mean_absolute_error: 6236.1973\n",
      "Epoch 299/500\n",
      "146/146 [==============================] - ETA: 0s - loss: 7382.8447 - mean_absolute_error: 7382.8447\n",
      "Epoch 299: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7382.8447 - mean_absolute_error: 7382.8447 - val_loss: 6242.1558 - val_mean_absolute_error: 6242.1558\n",
      "Epoch 300/500\n",
      "146/146 [==============================] - ETA: 0s - loss: 7205.0332 - mean_absolute_error: 7205.0332\n",
      "Epoch 300: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7205.0332 - mean_absolute_error: 7205.0332 - val_loss: 6218.9380 - val_mean_absolute_error: 6218.9380\n",
      "Epoch 301/500\n",
      "131/146 [=========================>....] - ETA: 0s - loss: 7297.0381 - mean_absolute_error: 7297.0381\n",
      "Epoch 301: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7316.9897 - mean_absolute_error: 7316.9897 - val_loss: 6216.4087 - val_mean_absolute_error: 6216.4087\n",
      "Epoch 302/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 7218.7646 - mean_absolute_error: 7218.7646\n",
      "Epoch 302: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7192.1694 - mean_absolute_error: 7192.1694 - val_loss: 6221.4341 - val_mean_absolute_error: 6221.4341\n",
      "Epoch 303/500\n",
      "122/146 [========================>.....] - ETA: 0s - loss: 7292.6655 - mean_absolute_error: 7292.6655\n",
      "Epoch 303: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7262.0488 - mean_absolute_error: 7262.0488 - val_loss: 6215.0068 - val_mean_absolute_error: 6215.0068\n",
      "Epoch 304/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 7264.9839 - mean_absolute_error: 7264.9839\n",
      "Epoch 304: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7250.6831 - mean_absolute_error: 7250.6831 - val_loss: 6218.5688 - val_mean_absolute_error: 6218.5688\n",
      "Epoch 305/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7214.8901 - mean_absolute_error: 7214.8901\n",
      "Epoch 305: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7219.5913 - mean_absolute_error: 7219.5913 - val_loss: 6220.9438 - val_mean_absolute_error: 6220.9438\n",
      "Epoch 306/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 7340.1953 - mean_absolute_error: 7340.1953\n",
      "Epoch 306: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7286.9409 - mean_absolute_error: 7286.9409 - val_loss: 6215.9814 - val_mean_absolute_error: 6215.9814\n",
      "Epoch 307/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 7251.7847 - mean_absolute_error: 7251.7847\n",
      "Epoch 307: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7258.9727 - mean_absolute_error: 7258.9727 - val_loss: 6223.2407 - val_mean_absolute_error: 6223.2407\n",
      "Epoch 308/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 7172.9619 - mean_absolute_error: 7172.9619\n",
      "Epoch 308: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7201.5190 - mean_absolute_error: 7201.5190 - val_loss: 6336.1733 - val_mean_absolute_error: 6336.1733\n",
      "Epoch 309/500\n",
      "136/146 [==========================>...] - ETA: 0s - loss: 7317.6953 - mean_absolute_error: 7317.6953\n",
      "Epoch 309: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7283.9150 - mean_absolute_error: 7283.9150 - val_loss: 6234.3062 - val_mean_absolute_error: 6234.3062\n",
      "Epoch 310/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7315.8882 - mean_absolute_error: 7315.8882\n",
      "Epoch 310: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7316.3486 - mean_absolute_error: 7316.3486 - val_loss: 6275.9839 - val_mean_absolute_error: 6275.9839\n",
      "Epoch 311/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 7327.0474 - mean_absolute_error: 7327.0474\n",
      "Epoch 311: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7322.0850 - mean_absolute_error: 7322.0850 - val_loss: 6214.8145 - val_mean_absolute_error: 6214.8145\n",
      "Epoch 312/500\n",
      "141/146 [===========================>..] - ETA: 0s - loss: 7191.1582 - mean_absolute_error: 7191.1582\n",
      "Epoch 312: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7210.5176 - mean_absolute_error: 7210.5176 - val_loss: 6214.9292 - val_mean_absolute_error: 6214.9292\n",
      "Epoch 313/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 7295.5820 - mean_absolute_error: 7295.5820\n",
      "Epoch 313: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7288.9321 - mean_absolute_error: 7288.9321 - val_loss: 6242.1709 - val_mean_absolute_error: 6242.1709\n",
      "Epoch 314/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 7378.7456 - mean_absolute_error: 7378.7456\n",
      "Epoch 314: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7387.8408 - mean_absolute_error: 7387.8408 - val_loss: 6234.1797 - val_mean_absolute_error: 6234.1797\n",
      "Epoch 315/500\n",
      "146/146 [==============================] - ETA: 0s - loss: 7206.5972 - mean_absolute_error: 7206.5972\n",
      "Epoch 315: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7206.5972 - mean_absolute_error: 7206.5972 - val_loss: 6213.9253 - val_mean_absolute_error: 6213.9253\n",
      "Epoch 316/500\n",
      "124/146 [========================>.....] - ETA: 0s - loss: 7309.8804 - mean_absolute_error: 7309.8804\n",
      "Epoch 316: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7269.6450 - mean_absolute_error: 7269.6450 - val_loss: 6216.1880 - val_mean_absolute_error: 6216.1880\n",
      "Epoch 317/500\n",
      "126/146 [========================>.....] - ETA: 0s - loss: 7322.3730 - mean_absolute_error: 7322.3730\n",
      "Epoch 317: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7285.0171 - mean_absolute_error: 7285.0171 - val_loss: 6213.9478 - val_mean_absolute_error: 6213.9478\n",
      "Epoch 318/500\n",
      "116/146 [======================>.......] - ETA: 0s - loss: 7335.9834 - mean_absolute_error: 7335.9834\n",
      "Epoch 318: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7327.9048 - mean_absolute_error: 7327.9048 - val_loss: 6223.6772 - val_mean_absolute_error: 6223.6772\n",
      "Epoch 319/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 7358.1665 - mean_absolute_error: 7358.1665\n",
      "Epoch 319: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7325.6348 - mean_absolute_error: 7325.6348 - val_loss: 6218.2461 - val_mean_absolute_error: 6218.2461\n",
      "Epoch 320/500\n",
      "126/146 [========================>.....] - ETA: 0s - loss: 7290.8018 - mean_absolute_error: 7290.8018\n",
      "Epoch 320: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7264.0454 - mean_absolute_error: 7264.0454 - val_loss: 6225.3574 - val_mean_absolute_error: 6225.3574\n",
      "Epoch 321/500\n",
      "128/146 [=========================>....] - ETA: 0s - loss: 7282.4243 - mean_absolute_error: 7282.4243\n",
      "Epoch 321: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7300.1567 - mean_absolute_error: 7300.1567 - val_loss: 6227.2534 - val_mean_absolute_error: 6227.2534\n",
      "Epoch 322/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 7270.4922 - mean_absolute_error: 7270.4922\n",
      "Epoch 322: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7257.7051 - mean_absolute_error: 7257.7051 - val_loss: 6213.9810 - val_mean_absolute_error: 6213.9810\n",
      "Epoch 323/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 7231.8818 - mean_absolute_error: 7231.8818\n",
      "Epoch 323: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7247.1382 - mean_absolute_error: 7247.1382 - val_loss: 6214.8828 - val_mean_absolute_error: 6214.8828\n",
      "Epoch 324/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 7283.4521 - mean_absolute_error: 7283.4521\n",
      "Epoch 324: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7294.5947 - mean_absolute_error: 7294.5947 - val_loss: 6225.8970 - val_mean_absolute_error: 6225.8970\n",
      "Epoch 325/500\n",
      "141/146 [===========================>..] - ETA: 0s - loss: 7318.5469 - mean_absolute_error: 7318.5469\n",
      "Epoch 325: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7286.2056 - mean_absolute_error: 7286.2056 - val_loss: 6228.6597 - val_mean_absolute_error: 6228.6597\n",
      "Epoch 326/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 7292.7622 - mean_absolute_error: 7292.7622\n",
      "Epoch 326: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7285.9390 - mean_absolute_error: 7285.9390 - val_loss: 6333.8970 - val_mean_absolute_error: 6333.8970\n",
      "Epoch 327/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 7264.3545 - mean_absolute_error: 7264.3545\n",
      "Epoch 327: mean_absolute_error did not improve from 7188.91064\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7283.6870 - mean_absolute_error: 7283.6870 - val_loss: 6277.9668 - val_mean_absolute_error: 6277.9668\n",
      "Epoch 328/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 7195.1416 - mean_absolute_error: 7195.1416\n",
      "Epoch 328: mean_absolute_error improved from 7188.91064 to 7173.81738, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7173.8174 - mean_absolute_error: 7173.8174 - val_loss: 6219.3325 - val_mean_absolute_error: 6219.3325\n",
      "Epoch 329/500\n",
      "126/146 [========================>.....] - ETA: 0s - loss: 7257.1318 - mean_absolute_error: 7257.1318\n",
      "Epoch 329: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7272.6343 - mean_absolute_error: 7272.6343 - val_loss: 6226.4595 - val_mean_absolute_error: 6226.4595\n",
      "Epoch 330/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 7319.0679 - mean_absolute_error: 7319.0679\n",
      "Epoch 330: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7333.2871 - mean_absolute_error: 7333.2871 - val_loss: 6220.0498 - val_mean_absolute_error: 6220.0498\n",
      "Epoch 331/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 7229.4282 - mean_absolute_error: 7229.4282\n",
      "Epoch 331: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7252.9331 - mean_absolute_error: 7252.9331 - val_loss: 6347.0425 - val_mean_absolute_error: 6347.0425\n",
      "Epoch 332/500\n",
      "144/146 [============================>.] - ETA: 0s - loss: 7214.2588 - mean_absolute_error: 7214.2588\n",
      "Epoch 332: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7199.8057 - mean_absolute_error: 7199.8057 - val_loss: 6229.1729 - val_mean_absolute_error: 6229.1729\n",
      "Epoch 333/500\n",
      "122/146 [========================>.....] - ETA: 0s - loss: 7155.2061 - mean_absolute_error: 7155.2061\n",
      "Epoch 333: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7224.7954 - mean_absolute_error: 7224.7954 - val_loss: 6219.9727 - val_mean_absolute_error: 6219.9727\n",
      "Epoch 334/500\n",
      "128/146 [=========================>....] - ETA: 0s - loss: 7294.1396 - mean_absolute_error: 7294.1396\n",
      "Epoch 334: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7293.3960 - mean_absolute_error: 7293.3960 - val_loss: 6249.8374 - val_mean_absolute_error: 6249.8374\n",
      "Epoch 335/500\n",
      "121/146 [=======================>......] - ETA: 0s - loss: 7297.0415 - mean_absolute_error: 7297.0415\n",
      "Epoch 335: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7263.4663 - mean_absolute_error: 7263.4663 - val_loss: 6220.1641 - val_mean_absolute_error: 6220.1641\n",
      "Epoch 336/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 7254.9468 - mean_absolute_error: 7254.9468\n",
      "Epoch 336: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7252.9590 - mean_absolute_error: 7252.9590 - val_loss: 6219.7476 - val_mean_absolute_error: 6219.7476\n",
      "Epoch 337/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 7224.8379 - mean_absolute_error: 7224.8379\n",
      "Epoch 337: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7203.7358 - mean_absolute_error: 7203.7358 - val_loss: 6459.3779 - val_mean_absolute_error: 6459.3779\n",
      "Epoch 338/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 7312.8594 - mean_absolute_error: 7312.8594\n",
      "Epoch 338: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7262.4893 - mean_absolute_error: 7262.4893 - val_loss: 6220.7407 - val_mean_absolute_error: 6220.7407\n",
      "Epoch 339/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7312.1089 - mean_absolute_error: 7312.1089\n",
      "Epoch 339: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7279.7114 - mean_absolute_error: 7279.7114 - val_loss: 6222.1533 - val_mean_absolute_error: 6222.1533\n",
      "Epoch 340/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 7240.6904 - mean_absolute_error: 7240.6904\n",
      "Epoch 340: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7295.4380 - mean_absolute_error: 7295.4380 - val_loss: 6227.3838 - val_mean_absolute_error: 6227.3838\n",
      "Epoch 341/500\n",
      "146/146 [==============================] - ETA: 0s - loss: 7473.8896 - mean_absolute_error: 7473.8896\n",
      "Epoch 341: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7473.8896 - mean_absolute_error: 7473.8896 - val_loss: 6272.8110 - val_mean_absolute_error: 6272.8110\n",
      "Epoch 342/500\n",
      "124/146 [========================>.....] - ETA: 0s - loss: 7232.6978 - mean_absolute_error: 7232.6978\n",
      "Epoch 342: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7237.2803 - mean_absolute_error: 7237.2803 - val_loss: 6222.5928 - val_mean_absolute_error: 6222.5928\n",
      "Epoch 343/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 7219.2207 - mean_absolute_error: 7219.2207\n",
      "Epoch 343: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7257.1689 - mean_absolute_error: 7257.1689 - val_loss: 6215.4634 - val_mean_absolute_error: 6215.4634\n",
      "Epoch 344/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 7256.8037 - mean_absolute_error: 7256.8037\n",
      "Epoch 344: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7277.8672 - mean_absolute_error: 7277.8672 - val_loss: 6237.5723 - val_mean_absolute_error: 6237.5723\n",
      "Epoch 345/500\n",
      "136/146 [==========================>...] - ETA: 0s - loss: 7217.4561 - mean_absolute_error: 7217.4561\n",
      "Epoch 345: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7232.5088 - mean_absolute_error: 7232.5088 - val_loss: 6225.0718 - val_mean_absolute_error: 6225.0718\n",
      "Epoch 346/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7348.8926 - mean_absolute_error: 7348.8926\n",
      "Epoch 346: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7299.3257 - mean_absolute_error: 7299.3257 - val_loss: 6257.5210 - val_mean_absolute_error: 6257.5210\n",
      "Epoch 347/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 7388.7173 - mean_absolute_error: 7388.7173\n",
      "Epoch 347: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7368.3555 - mean_absolute_error: 7368.3555 - val_loss: 6217.9565 - val_mean_absolute_error: 6217.9565\n",
      "Epoch 348/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 7241.4302 - mean_absolute_error: 7241.4302\n",
      "Epoch 348: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7228.1558 - mean_absolute_error: 7228.1558 - val_loss: 6217.1768 - val_mean_absolute_error: 6217.1768\n",
      "Epoch 349/500\n",
      "145/146 [============================>.] - ETA: 0s - loss: 7228.4478 - mean_absolute_error: 7228.4478\n",
      "Epoch 349: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7214.9385 - mean_absolute_error: 7214.9385 - val_loss: 6254.3633 - val_mean_absolute_error: 6254.3633\n",
      "Epoch 350/500\n",
      "121/146 [=======================>......] - ETA: 0s - loss: 7374.7607 - mean_absolute_error: 7374.7607\n",
      "Epoch 350: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7379.2178 - mean_absolute_error: 7379.2178 - val_loss: 6215.8838 - val_mean_absolute_error: 6215.8838\n",
      "Epoch 351/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 7218.4707 - mean_absolute_error: 7218.4707\n",
      "Epoch 351: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7255.0342 - mean_absolute_error: 7255.0342 - val_loss: 6213.9741 - val_mean_absolute_error: 6213.9741\n",
      "Epoch 352/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7236.3408 - mean_absolute_error: 7236.3408\n",
      "Epoch 352: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7237.7720 - mean_absolute_error: 7237.7720 - val_loss: 6216.9722 - val_mean_absolute_error: 6216.9722\n",
      "Epoch 353/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 7257.4863 - mean_absolute_error: 7257.4863\n",
      "Epoch 353: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7252.7739 - mean_absolute_error: 7252.7739 - val_loss: 6223.9980 - val_mean_absolute_error: 6223.9980\n",
      "Epoch 354/500\n",
      "128/146 [=========================>....] - ETA: 0s - loss: 7337.7383 - mean_absolute_error: 7337.7383\n",
      "Epoch 354: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7378.2261 - mean_absolute_error: 7378.2261 - val_loss: 6254.4517 - val_mean_absolute_error: 6254.4517\n",
      "Epoch 355/500\n",
      "117/146 [=======================>......] - ETA: 0s - loss: 7205.9424 - mean_absolute_error: 7205.9424\n",
      "Epoch 355: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7212.2998 - mean_absolute_error: 7212.2998 - val_loss: 6232.0854 - val_mean_absolute_error: 6232.0854\n",
      "Epoch 356/500\n",
      "121/146 [=======================>......] - ETA: 0s - loss: 7343.1143 - mean_absolute_error: 7343.1143\n",
      "Epoch 356: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7322.3340 - mean_absolute_error: 7322.3340 - val_loss: 6275.5684 - val_mean_absolute_error: 6275.5684\n",
      "Epoch 357/500\n",
      "145/146 [============================>.] - ETA: 0s - loss: 7315.0249 - mean_absolute_error: 7315.0249\n",
      "Epoch 357: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7306.2349 - mean_absolute_error: 7306.2349 - val_loss: 6215.6172 - val_mean_absolute_error: 6215.6172\n",
      "Epoch 358/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 7285.0752 - mean_absolute_error: 7285.0752\n",
      "Epoch 358: mean_absolute_error did not improve from 7173.81738\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7252.0308 - mean_absolute_error: 7252.0308 - val_loss: 6216.3369 - val_mean_absolute_error: 6216.3369\n",
      "Epoch 359/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7237.7002 - mean_absolute_error: 7237.7002\n",
      "Epoch 359: mean_absolute_error improved from 7173.81738 to 7154.54346, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7154.5435 - mean_absolute_error: 7154.5435 - val_loss: 6288.3350 - val_mean_absolute_error: 6288.3350\n",
      "Epoch 360/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 7255.5161 - mean_absolute_error: 7255.5161\n",
      "Epoch 360: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7243.0396 - mean_absolute_error: 7243.0396 - val_loss: 6215.8125 - val_mean_absolute_error: 6215.8125\n",
      "Epoch 361/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 7315.3999 - mean_absolute_error: 7315.3999\n",
      "Epoch 361: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7315.6289 - mean_absolute_error: 7315.6289 - val_loss: 6221.7544 - val_mean_absolute_error: 6221.7544\n",
      "Epoch 362/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 7205.1226 - mean_absolute_error: 7205.1226\n",
      "Epoch 362: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7239.9634 - mean_absolute_error: 7239.9634 - val_loss: 6376.7480 - val_mean_absolute_error: 6376.7480\n",
      "Epoch 363/500\n",
      "143/146 [============================>.] - ETA: 0s - loss: 7214.8789 - mean_absolute_error: 7214.8789\n",
      "Epoch 363: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7208.5654 - mean_absolute_error: 7208.5654 - val_loss: 6220.9902 - val_mean_absolute_error: 6220.9902\n",
      "Epoch 364/500\n",
      "123/146 [========================>.....] - ETA: 0s - loss: 7178.1318 - mean_absolute_error: 7178.1318\n",
      "Epoch 364: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7225.9146 - mean_absolute_error: 7225.9146 - val_loss: 6245.8062 - val_mean_absolute_error: 6245.8062\n",
      "Epoch 365/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 7257.8945 - mean_absolute_error: 7257.8945\n",
      "Epoch 365: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7224.0410 - mean_absolute_error: 7224.0410 - val_loss: 6221.4453 - val_mean_absolute_error: 6221.4453\n",
      "Epoch 366/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7270.4023 - mean_absolute_error: 7270.4023\n",
      "Epoch 366: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7221.0293 - mean_absolute_error: 7221.0293 - val_loss: 6217.9414 - val_mean_absolute_error: 6217.9414\n",
      "Epoch 367/500\n",
      "146/146 [==============================] - ETA: 0s - loss: 7613.7744 - mean_absolute_error: 7613.7744\n",
      "Epoch 367: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7613.7744 - mean_absolute_error: 7613.7744 - val_loss: 6291.8120 - val_mean_absolute_error: 6291.8120\n",
      "Epoch 368/500\n",
      "141/146 [===========================>..] - ETA: 0s - loss: 7342.9878 - mean_absolute_error: 7342.9878\n",
      "Epoch 368: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7351.3486 - mean_absolute_error: 7351.3486 - val_loss: 6389.5132 - val_mean_absolute_error: 6389.5132\n",
      "Epoch 369/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 7670.9023 - mean_absolute_error: 7670.9023\n",
      "Epoch 369: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7615.3096 - mean_absolute_error: 7615.3096 - val_loss: 6285.3760 - val_mean_absolute_error: 6285.3760\n",
      "Epoch 370/500\n",
      "119/146 [=======================>......] - ETA: 0s - loss: 7288.6753 - mean_absolute_error: 7288.6753\n",
      "Epoch 370: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7226.8784 - mean_absolute_error: 7226.8784 - val_loss: 6300.7583 - val_mean_absolute_error: 6300.7583\n",
      "Epoch 371/500\n",
      "141/146 [===========================>..] - ETA: 0s - loss: 7266.6562 - mean_absolute_error: 7266.6562\n",
      "Epoch 371: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7230.8159 - mean_absolute_error: 7230.8159 - val_loss: 6236.0181 - val_mean_absolute_error: 6236.0181\n",
      "Epoch 372/500\n",
      "141/146 [===========================>..] - ETA: 0s - loss: 7244.5176 - mean_absolute_error: 7244.5176\n",
      "Epoch 372: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7265.1406 - mean_absolute_error: 7265.1406 - val_loss: 6222.6084 - val_mean_absolute_error: 6222.6084\n",
      "Epoch 373/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 7239.5181 - mean_absolute_error: 7239.5181\n",
      "Epoch 373: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7245.8311 - mean_absolute_error: 7245.8311 - val_loss: 6401.3955 - val_mean_absolute_error: 6401.3955\n",
      "Epoch 374/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 7199.4858 - mean_absolute_error: 7199.4858\n",
      "Epoch 374: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7210.3472 - mean_absolute_error: 7210.3472 - val_loss: 6226.1299 - val_mean_absolute_error: 6226.1299\n",
      "Epoch 375/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 7237.9146 - mean_absolute_error: 7237.9146\n",
      "Epoch 375: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7187.4888 - mean_absolute_error: 7187.4888 - val_loss: 6249.2295 - val_mean_absolute_error: 6249.2295\n",
      "Epoch 376/500\n",
      "131/146 [=========================>....] - ETA: 0s - loss: 7245.5132 - mean_absolute_error: 7245.5132\n",
      "Epoch 376: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7253.2715 - mean_absolute_error: 7253.2715 - val_loss: 6221.3662 - val_mean_absolute_error: 6221.3662\n",
      "Epoch 377/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 7289.8979 - mean_absolute_error: 7289.8979\n",
      "Epoch 377: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7297.1836 - mean_absolute_error: 7297.1836 - val_loss: 6214.0122 - val_mean_absolute_error: 6214.0122\n",
      "Epoch 378/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 7227.4355 - mean_absolute_error: 7227.4355\n",
      "Epoch 378: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7259.0625 - mean_absolute_error: 7259.0625 - val_loss: 6372.5786 - val_mean_absolute_error: 6372.5786\n",
      "Epoch 379/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 7219.8960 - mean_absolute_error: 7219.8960\n",
      "Epoch 379: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7201.8442 - mean_absolute_error: 7201.8442 - val_loss: 6266.5430 - val_mean_absolute_error: 6266.5430\n",
      "Epoch 380/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 7374.4663 - mean_absolute_error: 7374.4663\n",
      "Epoch 380: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7317.2949 - mean_absolute_error: 7317.2949 - val_loss: 6224.1968 - val_mean_absolute_error: 6224.1968\n",
      "Epoch 381/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7235.6001 - mean_absolute_error: 7235.6001\n",
      "Epoch 381: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7183.6206 - mean_absolute_error: 7183.6206 - val_loss: 6234.8579 - val_mean_absolute_error: 6234.8579\n",
      "Epoch 382/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 7268.5195 - mean_absolute_error: 7268.5195\n",
      "Epoch 382: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7293.9253 - mean_absolute_error: 7293.9253 - val_loss: 6315.2510 - val_mean_absolute_error: 6315.2510\n",
      "Epoch 383/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 7259.4619 - mean_absolute_error: 7259.4619\n",
      "Epoch 383: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7278.7617 - mean_absolute_error: 7278.7617 - val_loss: 6239.9683 - val_mean_absolute_error: 6239.9683\n",
      "Epoch 384/500\n",
      "124/146 [========================>.....] - ETA: 0s - loss: 7189.0278 - mean_absolute_error: 7189.0278\n",
      "Epoch 384: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7197.4482 - mean_absolute_error: 7197.4482 - val_loss: 6286.6816 - val_mean_absolute_error: 6286.6816\n",
      "Epoch 385/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7170.3320 - mean_absolute_error: 7170.3320\n",
      "Epoch 385: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7248.4595 - mean_absolute_error: 7248.4595 - val_loss: 6314.7397 - val_mean_absolute_error: 6314.7397\n",
      "Epoch 386/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 7281.0366 - mean_absolute_error: 7281.0366\n",
      "Epoch 386: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7228.7773 - mean_absolute_error: 7228.7773 - val_loss: 6223.7876 - val_mean_absolute_error: 6223.7876\n",
      "Epoch 387/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 7210.0220 - mean_absolute_error: 7210.0220\n",
      "Epoch 387: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7226.9580 - mean_absolute_error: 7226.9580 - val_loss: 6223.0342 - val_mean_absolute_error: 6223.0342\n",
      "Epoch 388/500\n",
      "122/146 [========================>.....] - ETA: 0s - loss: 7266.0498 - mean_absolute_error: 7266.0498\n",
      "Epoch 388: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7262.4146 - mean_absolute_error: 7262.4146 - val_loss: 6302.9248 - val_mean_absolute_error: 6302.9248\n",
      "Epoch 389/500\n",
      "143/146 [============================>.] - ETA: 0s - loss: 7265.3169 - mean_absolute_error: 7265.3169\n",
      "Epoch 389: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7230.3486 - mean_absolute_error: 7230.3486 - val_loss: 6219.5088 - val_mean_absolute_error: 6219.5088\n",
      "Epoch 390/500\n",
      "136/146 [==========================>...] - ETA: 0s - loss: 7286.5356 - mean_absolute_error: 7286.5356\n",
      "Epoch 390: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7302.9023 - mean_absolute_error: 7302.9023 - val_loss: 6227.0425 - val_mean_absolute_error: 6227.0425\n",
      "Epoch 391/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 7284.7964 - mean_absolute_error: 7284.7964\n",
      "Epoch 391: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7264.7637 - mean_absolute_error: 7264.7637 - val_loss: 6361.2437 - val_mean_absolute_error: 6361.2437\n",
      "Epoch 392/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7250.7539 - mean_absolute_error: 7250.7539\n",
      "Epoch 392: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7233.6846 - mean_absolute_error: 7233.6846 - val_loss: 6242.1523 - val_mean_absolute_error: 6242.1523\n",
      "Epoch 393/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7155.9185 - mean_absolute_error: 7155.9185\n",
      "Epoch 393: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7209.8262 - mean_absolute_error: 7209.8262 - val_loss: 6282.7964 - val_mean_absolute_error: 6282.7964\n",
      "Epoch 394/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7195.1602 - mean_absolute_error: 7195.1602\n",
      "Epoch 394: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7188.2349 - mean_absolute_error: 7188.2349 - val_loss: 6287.5801 - val_mean_absolute_error: 6287.5801\n",
      "Epoch 395/500\n",
      "143/146 [============================>.] - ETA: 0s - loss: 7227.5205 - mean_absolute_error: 7227.5205\n",
      "Epoch 395: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7223.3608 - mean_absolute_error: 7223.3608 - val_loss: 6229.5088 - val_mean_absolute_error: 6229.5088\n",
      "Epoch 396/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 7253.5933 - mean_absolute_error: 7253.5933\n",
      "Epoch 396: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7263.0488 - mean_absolute_error: 7263.0488 - val_loss: 6218.5820 - val_mean_absolute_error: 6218.5820\n",
      "Epoch 397/500\n",
      "123/146 [========================>.....] - ETA: 0s - loss: 7211.9292 - mean_absolute_error: 7211.9292\n",
      "Epoch 397: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7186.4004 - mean_absolute_error: 7186.4004 - val_loss: 6299.5171 - val_mean_absolute_error: 6299.5171\n",
      "Epoch 398/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 7217.1245 - mean_absolute_error: 7217.1245\n",
      "Epoch 398: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7237.6968 - mean_absolute_error: 7237.6968 - val_loss: 6224.2793 - val_mean_absolute_error: 6224.2793\n",
      "Epoch 399/500\n",
      "144/146 [============================>.] - ETA: 0s - loss: 7270.3320 - mean_absolute_error: 7270.3320\n",
      "Epoch 399: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7267.4316 - mean_absolute_error: 7267.4316 - val_loss: 6235.0488 - val_mean_absolute_error: 6235.0488\n",
      "Epoch 400/500\n",
      "136/146 [==========================>...] - ETA: 0s - loss: 7364.9561 - mean_absolute_error: 7364.9561\n",
      "Epoch 400: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7322.0728 - mean_absolute_error: 7322.0728 - val_loss: 6219.1270 - val_mean_absolute_error: 6219.1270\n",
      "Epoch 401/500\n",
      "145/146 [============================>.] - ETA: 0s - loss: 7258.8164 - mean_absolute_error: 7258.8164\n",
      "Epoch 401: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7248.7505 - mean_absolute_error: 7248.7505 - val_loss: 6282.7451 - val_mean_absolute_error: 6282.7451\n",
      "Epoch 402/500\n",
      "145/146 [============================>.] - ETA: 0s - loss: 7274.1655 - mean_absolute_error: 7274.1655\n",
      "Epoch 402: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7284.0928 - mean_absolute_error: 7284.0928 - val_loss: 6223.6919 - val_mean_absolute_error: 6223.6919\n",
      "Epoch 403/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 7147.3921 - mean_absolute_error: 7147.3921\n",
      "Epoch 403: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7231.3384 - mean_absolute_error: 7231.3384 - val_loss: 6222.6836 - val_mean_absolute_error: 6222.6836\n",
      "Epoch 404/500\n",
      "128/146 [=========================>....] - ETA: 0s - loss: 7299.9707 - mean_absolute_error: 7299.9707\n",
      "Epoch 404: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7266.3496 - mean_absolute_error: 7266.3496 - val_loss: 6291.0537 - val_mean_absolute_error: 6291.0537\n",
      "Epoch 405/500\n",
      "146/146 [==============================] - ETA: 0s - loss: 7308.4771 - mean_absolute_error: 7308.4771\n",
      "Epoch 405: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7308.4771 - mean_absolute_error: 7308.4771 - val_loss: 6222.9419 - val_mean_absolute_error: 6222.9419\n",
      "Epoch 406/500\n",
      "136/146 [==========================>...] - ETA: 0s - loss: 7298.6123 - mean_absolute_error: 7298.6123\n",
      "Epoch 406: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7273.8159 - mean_absolute_error: 7273.8159 - val_loss: 6215.0830 - val_mean_absolute_error: 6215.0830\n",
      "Epoch 407/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 7245.4595 - mean_absolute_error: 7245.4595\n",
      "Epoch 407: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7237.0928 - mean_absolute_error: 7237.0928 - val_loss: 6319.1265 - val_mean_absolute_error: 6319.1265\n",
      "Epoch 408/500\n",
      "125/146 [========================>.....] - ETA: 0s - loss: 7237.3711 - mean_absolute_error: 7237.3711\n",
      "Epoch 408: mean_absolute_error did not improve from 7154.54346\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7198.7891 - mean_absolute_error: 7198.7891 - val_loss: 6240.7017 - val_mean_absolute_error: 6240.7017\n",
      "Epoch 409/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7171.2871 - mean_absolute_error: 7171.2871\n",
      "Epoch 409: mean_absolute_error improved from 7154.54346 to 7143.53516, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7143.5352 - mean_absolute_error: 7143.5352 - val_loss: 6219.6953 - val_mean_absolute_error: 6219.6953\n",
      "Epoch 410/500\n",
      "144/146 [============================>.] - ETA: 0s - loss: 7167.1929 - mean_absolute_error: 7167.1929\n",
      "Epoch 410: mean_absolute_error did not improve from 7143.53516\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7157.6646 - mean_absolute_error: 7157.6646 - val_loss: 6217.7388 - val_mean_absolute_error: 6217.7388\n",
      "Epoch 411/500\n",
      "146/146 [==============================] - ETA: 0s - loss: 7264.1440 - mean_absolute_error: 7264.1440\n",
      "Epoch 411: mean_absolute_error did not improve from 7143.53516\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7264.1440 - mean_absolute_error: 7264.1440 - val_loss: 6217.0591 - val_mean_absolute_error: 6217.0591\n",
      "Epoch 412/500\n",
      "136/146 [==========================>...] - ETA: 0s - loss: 7243.4463 - mean_absolute_error: 7243.4463\n",
      "Epoch 412: mean_absolute_error did not improve from 7143.53516\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7226.6128 - mean_absolute_error: 7226.6128 - val_loss: 6220.3882 - val_mean_absolute_error: 6220.3882\n",
      "Epoch 413/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 7546.3486 - mean_absolute_error: 7546.3486\n",
      "Epoch 413: mean_absolute_error did not improve from 7143.53516\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7557.0430 - mean_absolute_error: 7557.0430 - val_loss: 6277.3306 - val_mean_absolute_error: 6277.3306\n",
      "Epoch 414/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 7387.2432 - mean_absolute_error: 7387.2432\n",
      "Epoch 414: mean_absolute_error did not improve from 7143.53516\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7361.7686 - mean_absolute_error: 7361.7686 - val_loss: 6229.6953 - val_mean_absolute_error: 6229.6953\n",
      "Epoch 415/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 7258.9849 - mean_absolute_error: 7258.9849\n",
      "Epoch 415: mean_absolute_error did not improve from 7143.53516\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7229.0474 - mean_absolute_error: 7229.0474 - val_loss: 6229.1450 - val_mean_absolute_error: 6229.1450\n",
      "Epoch 416/500\n",
      "125/146 [========================>.....] - ETA: 0s - loss: 7163.4077 - mean_absolute_error: 7163.4077\n",
      "Epoch 416: mean_absolute_error did not improve from 7143.53516\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7241.6118 - mean_absolute_error: 7241.6118 - val_loss: 6232.4214 - val_mean_absolute_error: 6232.4214\n",
      "Epoch 417/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 7226.9707 - mean_absolute_error: 7226.9707\n",
      "Epoch 417: mean_absolute_error did not improve from 7143.53516\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7227.6118 - mean_absolute_error: 7227.6118 - val_loss: 6226.3096 - val_mean_absolute_error: 6226.3096\n",
      "Epoch 418/500\n",
      "145/146 [============================>.] - ETA: 0s - loss: 7254.0869 - mean_absolute_error: 7254.0869\n",
      "Epoch 418: mean_absolute_error did not improve from 7143.53516\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7236.5098 - mean_absolute_error: 7236.5098 - val_loss: 6225.4897 - val_mean_absolute_error: 6225.4897\n",
      "Epoch 419/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7218.8525 - mean_absolute_error: 7218.8525\n",
      "Epoch 419: mean_absolute_error did not improve from 7143.53516\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7208.8477 - mean_absolute_error: 7208.8477 - val_loss: 6229.5962 - val_mean_absolute_error: 6229.5962\n",
      "Epoch 420/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 7117.7373 - mean_absolute_error: 7117.7373\n",
      "Epoch 420: mean_absolute_error did not improve from 7143.53516\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7157.5928 - mean_absolute_error: 7157.5928 - val_loss: 6234.7944 - val_mean_absolute_error: 6234.7944\n",
      "Epoch 421/500\n",
      "126/146 [========================>.....] - ETA: 0s - loss: 7256.3330 - mean_absolute_error: 7256.3330\n",
      "Epoch 421: mean_absolute_error did not improve from 7143.53516\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7225.1816 - mean_absolute_error: 7225.1816 - val_loss: 6232.4351 - val_mean_absolute_error: 6232.4351\n",
      "Epoch 422/500\n",
      "146/146 [==============================] - ETA: 0s - loss: 7313.4917 - mean_absolute_error: 7313.4917\n",
      "Epoch 422: mean_absolute_error did not improve from 7143.53516\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7313.4917 - mean_absolute_error: 7313.4917 - val_loss: 6243.5693 - val_mean_absolute_error: 6243.5693\n",
      "Epoch 423/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7301.2544 - mean_absolute_error: 7301.2544\n",
      "Epoch 423: mean_absolute_error did not improve from 7143.53516\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7314.1260 - mean_absolute_error: 7314.1260 - val_loss: 6220.4688 - val_mean_absolute_error: 6220.4688\n",
      "Epoch 424/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 7272.6816 - mean_absolute_error: 7272.6816\n",
      "Epoch 424: mean_absolute_error did not improve from 7143.53516\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7265.3926 - mean_absolute_error: 7265.3926 - val_loss: 6230.8960 - val_mean_absolute_error: 6230.8960\n",
      "Epoch 425/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 7085.6509 - mean_absolute_error: 7085.6509\n",
      "Epoch 425: mean_absolute_error improved from 7143.53516 to 7073.61328, saving model to .\\checkpoints\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7073.6133 - mean_absolute_error: 7073.6133 - val_loss: 6215.2358 - val_mean_absolute_error: 6215.2358\n",
      "Epoch 426/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 7235.9390 - mean_absolute_error: 7235.9390\n",
      "Epoch 426: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7212.3721 - mean_absolute_error: 7212.3721 - val_loss: 6312.4351 - val_mean_absolute_error: 6312.4351\n",
      "Epoch 427/500\n",
      "121/146 [=======================>......] - ETA: 0s - loss: 7157.6582 - mean_absolute_error: 7157.6582\n",
      "Epoch 427: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7268.6084 - mean_absolute_error: 7268.6084 - val_loss: 6220.0820 - val_mean_absolute_error: 6220.0820\n",
      "Epoch 428/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 7218.5352 - mean_absolute_error: 7218.5352\n",
      "Epoch 428: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7234.1802 - mean_absolute_error: 7234.1802 - val_loss: 6269.3145 - val_mean_absolute_error: 6269.3145\n",
      "Epoch 429/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 7287.3218 - mean_absolute_error: 7287.3218\n",
      "Epoch 429: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7191.4824 - mean_absolute_error: 7191.4824 - val_loss: 6223.3843 - val_mean_absolute_error: 6223.3843\n",
      "Epoch 430/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 7258.0347 - mean_absolute_error: 7258.0347\n",
      "Epoch 430: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7304.1782 - mean_absolute_error: 7304.1782 - val_loss: 6245.0107 - val_mean_absolute_error: 6245.0107\n",
      "Epoch 431/500\n",
      "122/146 [========================>.....] - ETA: 0s - loss: 7226.7686 - mean_absolute_error: 7226.7686\n",
      "Epoch 431: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7259.9160 - mean_absolute_error: 7259.9160 - val_loss: 6219.6348 - val_mean_absolute_error: 6219.6348\n",
      "Epoch 432/500\n",
      "125/146 [========================>.....] - ETA: 0s - loss: 7288.4072 - mean_absolute_error: 7288.4072\n",
      "Epoch 432: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7251.9365 - mean_absolute_error: 7251.9365 - val_loss: 6215.6484 - val_mean_absolute_error: 6215.6484\n",
      "Epoch 433/500\n",
      "136/146 [==========================>...] - ETA: 0s - loss: 7150.5186 - mean_absolute_error: 7150.5186\n",
      "Epoch 433: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7135.7358 - mean_absolute_error: 7135.7358 - val_loss: 6248.9888 - val_mean_absolute_error: 6248.9888\n",
      "Epoch 434/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 7171.1323 - mean_absolute_error: 7171.1323\n",
      "Epoch 434: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7203.7808 - mean_absolute_error: 7203.7808 - val_loss: 6227.3779 - val_mean_absolute_error: 6227.3779\n",
      "Epoch 435/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 7319.9858 - mean_absolute_error: 7319.9858\n",
      "Epoch 435: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7322.3232 - mean_absolute_error: 7322.3232 - val_loss: 6235.9463 - val_mean_absolute_error: 6235.9463\n",
      "Epoch 436/500\n",
      "141/146 [===========================>..] - ETA: 0s - loss: 7220.0781 - mean_absolute_error: 7220.0781\n",
      "Epoch 436: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7186.7031 - mean_absolute_error: 7186.7031 - val_loss: 6217.8008 - val_mean_absolute_error: 6217.8008\n",
      "Epoch 437/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7176.7295 - mean_absolute_error: 7176.7295\n",
      "Epoch 437: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7228.2803 - mean_absolute_error: 7228.2803 - val_loss: 6218.4736 - val_mean_absolute_error: 6218.4736\n",
      "Epoch 438/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 7303.7788 - mean_absolute_error: 7303.7788\n",
      "Epoch 438: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7289.2114 - mean_absolute_error: 7289.2114 - val_loss: 6233.0166 - val_mean_absolute_error: 6233.0166\n",
      "Epoch 439/500\n",
      "146/146 [==============================] - ETA: 0s - loss: 7120.7773 - mean_absolute_error: 7120.7773\n",
      "Epoch 439: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7120.7773 - mean_absolute_error: 7120.7773 - val_loss: 6219.0576 - val_mean_absolute_error: 6219.0576\n",
      "Epoch 440/500\n",
      "145/146 [============================>.] - ETA: 0s - loss: 7235.4517 - mean_absolute_error: 7235.4517\n",
      "Epoch 440: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7237.7354 - mean_absolute_error: 7237.7354 - val_loss: 6214.9824 - val_mean_absolute_error: 6214.9824\n",
      "Epoch 441/500\n",
      "141/146 [===========================>..] - ETA: 0s - loss: 7216.3091 - mean_absolute_error: 7216.3091\n",
      "Epoch 441: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7228.5620 - mean_absolute_error: 7228.5620 - val_loss: 6278.7080 - val_mean_absolute_error: 6278.7080\n",
      "Epoch 442/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 7262.9473 - mean_absolute_error: 7262.9473\n",
      "Epoch 442: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7273.5151 - mean_absolute_error: 7273.5151 - val_loss: 6266.3398 - val_mean_absolute_error: 6266.3398\n",
      "Epoch 443/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 7241.3369 - mean_absolute_error: 7241.3369\n",
      "Epoch 443: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7254.2603 - mean_absolute_error: 7254.2603 - val_loss: 6263.1045 - val_mean_absolute_error: 6263.1045\n",
      "Epoch 444/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 7202.3159 - mean_absolute_error: 7202.3159\n",
      "Epoch 444: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7207.5928 - mean_absolute_error: 7207.5928 - val_loss: 6219.8945 - val_mean_absolute_error: 6219.8945\n",
      "Epoch 445/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 7251.2666 - mean_absolute_error: 7251.2666\n",
      "Epoch 445: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7238.3652 - mean_absolute_error: 7238.3652 - val_loss: 6279.2856 - val_mean_absolute_error: 6279.2856\n",
      "Epoch 446/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 7331.0161 - mean_absolute_error: 7331.0161\n",
      "Epoch 446: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7301.6289 - mean_absolute_error: 7301.6289 - val_loss: 6219.3789 - val_mean_absolute_error: 6219.3789\n",
      "Epoch 447/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 7271.4609 - mean_absolute_error: 7271.4609\n",
      "Epoch 447: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7230.4526 - mean_absolute_error: 7230.4526 - val_loss: 6229.5249 - val_mean_absolute_error: 6229.5249\n",
      "Epoch 448/500\n",
      "124/146 [========================>.....] - ETA: 0s - loss: 7210.3789 - mean_absolute_error: 7210.3789\n",
      "Epoch 448: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7161.4561 - mean_absolute_error: 7161.4561 - val_loss: 6274.8198 - val_mean_absolute_error: 6274.8198\n",
      "Epoch 449/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 7330.0620 - mean_absolute_error: 7330.0620\n",
      "Epoch 449: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7294.6660 - mean_absolute_error: 7294.6660 - val_loss: 6219.7925 - val_mean_absolute_error: 6219.7925\n",
      "Epoch 450/500\n",
      "144/146 [============================>.] - ETA: 0s - loss: 7135.5181 - mean_absolute_error: 7135.5181\n",
      "Epoch 450: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7148.7256 - mean_absolute_error: 7148.7256 - val_loss: 6298.6221 - val_mean_absolute_error: 6298.6221\n",
      "Epoch 451/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 7255.5249 - mean_absolute_error: 7255.5249\n",
      "Epoch 451: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7245.3789 - mean_absolute_error: 7245.3789 - val_loss: 6222.7129 - val_mean_absolute_error: 6222.7129\n",
      "Epoch 452/500\n",
      "146/146 [==============================] - ETA: 0s - loss: 7291.9150 - mean_absolute_error: 7291.9150\n",
      "Epoch 452: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7291.9150 - mean_absolute_error: 7291.9150 - val_loss: 6232.7656 - val_mean_absolute_error: 6232.7656\n",
      "Epoch 453/500\n",
      "134/146 [==========================>...] - ETA: 0s - loss: 7140.5107 - mean_absolute_error: 7140.5107\n",
      "Epoch 453: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7181.4448 - mean_absolute_error: 7181.4448 - val_loss: 6223.5039 - val_mean_absolute_error: 6223.5039\n",
      "Epoch 454/500\n",
      "130/146 [=========================>....] - ETA: 0s - loss: 7233.5181 - mean_absolute_error: 7233.5181\n",
      "Epoch 454: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7212.0854 - mean_absolute_error: 7212.0854 - val_loss: 6221.1128 - val_mean_absolute_error: 6221.1128\n",
      "Epoch 455/500\n",
      "128/146 [=========================>....] - ETA: 0s - loss: 7198.7520 - mean_absolute_error: 7198.7520\n",
      "Epoch 455: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7219.7378 - mean_absolute_error: 7219.7378 - val_loss: 6294.9189 - val_mean_absolute_error: 6294.9189\n",
      "Epoch 456/500\n",
      "128/146 [=========================>....] - ETA: 0s - loss: 7082.1514 - mean_absolute_error: 7082.1514\n",
      "Epoch 456: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7168.6201 - mean_absolute_error: 7168.6201 - val_loss: 6238.5435 - val_mean_absolute_error: 6238.5435\n",
      "Epoch 457/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 7170.8003 - mean_absolute_error: 7170.8003\n",
      "Epoch 457: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7160.4170 - mean_absolute_error: 7160.4170 - val_loss: 6239.8257 - val_mean_absolute_error: 6239.8257\n",
      "Epoch 458/500\n",
      "141/146 [===========================>..] - ETA: 0s - loss: 7202.5732 - mean_absolute_error: 7202.5732\n",
      "Epoch 458: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7232.3315 - mean_absolute_error: 7232.3315 - val_loss: 6259.6104 - val_mean_absolute_error: 6259.6104\n",
      "Epoch 459/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 7178.7476 - mean_absolute_error: 7178.7476\n",
      "Epoch 459: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7157.9575 - mean_absolute_error: 7157.9575 - val_loss: 6221.2222 - val_mean_absolute_error: 6221.2222\n",
      "Epoch 460/500\n",
      "128/146 [=========================>....] - ETA: 0s - loss: 7192.4536 - mean_absolute_error: 7192.4536\n",
      "Epoch 460: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7209.0479 - mean_absolute_error: 7209.0479 - val_loss: 6350.3745 - val_mean_absolute_error: 6350.3745\n",
      "Epoch 461/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 7248.5483 - mean_absolute_error: 7248.5483\n",
      "Epoch 461: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7296.7617 - mean_absolute_error: 7296.7617 - val_loss: 6287.9302 - val_mean_absolute_error: 6287.9302\n",
      "Epoch 462/500\n",
      "123/146 [========================>.....] - ETA: 0s - loss: 7171.5195 - mean_absolute_error: 7171.5195\n",
      "Epoch 462: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7150.7783 - mean_absolute_error: 7150.7783 - val_loss: 6295.1299 - val_mean_absolute_error: 6295.1299\n",
      "Epoch 463/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7161.0278 - mean_absolute_error: 7161.0278\n",
      "Epoch 463: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7172.4849 - mean_absolute_error: 7172.4849 - val_loss: 6222.4756 - val_mean_absolute_error: 6222.4756\n",
      "Epoch 464/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7226.3037 - mean_absolute_error: 7226.3037\n",
      "Epoch 464: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7217.7568 - mean_absolute_error: 7217.7568 - val_loss: 6214.1543 - val_mean_absolute_error: 6214.1543\n",
      "Epoch 465/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7205.9858 - mean_absolute_error: 7205.9858\n",
      "Epoch 465: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7184.6460 - mean_absolute_error: 7184.6460 - val_loss: 6241.4424 - val_mean_absolute_error: 6241.4424\n",
      "Epoch 466/500\n",
      "122/146 [========================>.....] - ETA: 0s - loss: 7271.6045 - mean_absolute_error: 7271.6045\n",
      "Epoch 466: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7238.0259 - mean_absolute_error: 7238.0259 - val_loss: 6237.5400 - val_mean_absolute_error: 6237.5400\n",
      "Epoch 467/500\n",
      "145/146 [============================>.] - ETA: 0s - loss: 7118.8184 - mean_absolute_error: 7118.8184\n",
      "Epoch 467: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7122.0459 - mean_absolute_error: 7122.0459 - val_loss: 6235.3442 - val_mean_absolute_error: 6235.3442\n",
      "Epoch 468/500\n",
      "128/146 [=========================>....] - ETA: 0s - loss: 7182.8428 - mean_absolute_error: 7182.8428\n",
      "Epoch 468: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7190.1816 - mean_absolute_error: 7190.1816 - val_loss: 6230.5479 - val_mean_absolute_error: 6230.5479\n",
      "Epoch 469/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 7204.9092 - mean_absolute_error: 7204.9092\n",
      "Epoch 469: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7210.7163 - mean_absolute_error: 7210.7163 - val_loss: 6221.0640 - val_mean_absolute_error: 6221.0640\n",
      "Epoch 470/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 7270.5352 - mean_absolute_error: 7270.5352\n",
      "Epoch 470: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7240.9014 - mean_absolute_error: 7240.9014 - val_loss: 6240.2944 - val_mean_absolute_error: 6240.2944\n",
      "Epoch 471/500\n",
      "141/146 [===========================>..] - ETA: 0s - loss: 7230.9688 - mean_absolute_error: 7230.9688\n",
      "Epoch 471: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 7217.0127 - mean_absolute_error: 7217.0127 - val_loss: 6222.8584 - val_mean_absolute_error: 6222.8584\n",
      "Epoch 472/500\n",
      "138/146 [===========================>..] - ETA: 0s - loss: 7188.2422 - mean_absolute_error: 7188.2422\n",
      "Epoch 472: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 7151.3804 - mean_absolute_error: 7151.3804 - val_loss: 6216.1699 - val_mean_absolute_error: 6216.1699\n",
      "Epoch 473/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7164.9053 - mean_absolute_error: 7164.9053\n",
      "Epoch 473: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7197.7822 - mean_absolute_error: 7197.7822 - val_loss: 6225.4297 - val_mean_absolute_error: 6225.4297\n",
      "Epoch 474/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7205.6592 - mean_absolute_error: 7205.6592\n",
      "Epoch 474: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7184.9316 - mean_absolute_error: 7184.9316 - val_loss: 6371.1699 - val_mean_absolute_error: 6371.1699\n",
      "Epoch 475/500\n",
      "120/146 [=======================>......] - ETA: 0s - loss: 7265.7515 - mean_absolute_error: 7265.7515\n",
      "Epoch 475: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7169.8521 - mean_absolute_error: 7169.8521 - val_loss: 6281.5884 - val_mean_absolute_error: 6281.5884\n",
      "Epoch 476/500\n",
      "133/146 [==========================>...] - ETA: 0s - loss: 7107.4385 - mean_absolute_error: 7107.4385\n",
      "Epoch 476: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7135.9883 - mean_absolute_error: 7135.9883 - val_loss: 6260.4307 - val_mean_absolute_error: 6260.4307\n",
      "Epoch 477/500\n",
      "132/146 [==========================>...] - ETA: 0s - loss: 7257.7197 - mean_absolute_error: 7257.7197\n",
      "Epoch 477: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7172.0562 - mean_absolute_error: 7172.0562 - val_loss: 6215.8477 - val_mean_absolute_error: 6215.8477\n",
      "Epoch 478/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 7172.7427 - mean_absolute_error: 7172.7427\n",
      "Epoch 478: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7169.0688 - mean_absolute_error: 7169.0688 - val_loss: 6230.2461 - val_mean_absolute_error: 6230.2461\n",
      "Epoch 479/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 7154.4453 - mean_absolute_error: 7154.4453\n",
      "Epoch 479: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7167.4272 - mean_absolute_error: 7167.4272 - val_loss: 6222.4937 - val_mean_absolute_error: 6222.4937\n",
      "Epoch 480/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 7211.1694 - mean_absolute_error: 7211.1694\n",
      "Epoch 480: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7194.8125 - mean_absolute_error: 7194.8125 - val_loss: 6233.8306 - val_mean_absolute_error: 6233.8306\n",
      "Epoch 481/500\n",
      "120/146 [=======================>......] - ETA: 0s - loss: 7154.2495 - mean_absolute_error: 7154.2495\n",
      "Epoch 481: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7182.9849 - mean_absolute_error: 7182.9849 - val_loss: 6229.5996 - val_mean_absolute_error: 6229.5996\n",
      "Epoch 482/500\n",
      "141/146 [===========================>..] - ETA: 0s - loss: 7183.5928 - mean_absolute_error: 7183.5928\n",
      "Epoch 482: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7187.4980 - mean_absolute_error: 7187.4980 - val_loss: 6290.7759 - val_mean_absolute_error: 6290.7759\n",
      "Epoch 483/500\n",
      "141/146 [===========================>..] - ETA: 0s - loss: 7160.1055 - mean_absolute_error: 7160.1055\n",
      "Epoch 483: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 1s 3ms/step - loss: 7164.1968 - mean_absolute_error: 7164.1968 - val_loss: 6214.3486 - val_mean_absolute_error: 6214.3486\n",
      "Epoch 484/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7103.4463 - mean_absolute_error: 7103.4463\n",
      "Epoch 484: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7149.7554 - mean_absolute_error: 7149.7554 - val_loss: 6434.6860 - val_mean_absolute_error: 6434.6860\n",
      "Epoch 485/500\n",
      "124/146 [========================>.....] - ETA: 0s - loss: 7176.3555 - mean_absolute_error: 7176.3555\n",
      "Epoch 485: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7166.0229 - mean_absolute_error: 7166.0229 - val_loss: 6217.4780 - val_mean_absolute_error: 6217.4780\n",
      "Epoch 486/500\n",
      "137/146 [===========================>..] - ETA: 0s - loss: 7184.0664 - mean_absolute_error: 7184.0664\n",
      "Epoch 486: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7184.7959 - mean_absolute_error: 7184.7959 - val_loss: 6412.2495 - val_mean_absolute_error: 6412.2495\n",
      "Epoch 487/500\n",
      "146/146 [==============================] - ETA: 0s - loss: 7202.6519 - mean_absolute_error: 7202.6519\n",
      "Epoch 487: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7202.6519 - mean_absolute_error: 7202.6519 - val_loss: 6345.9121 - val_mean_absolute_error: 6345.9121\n",
      "Epoch 488/500\n",
      "146/146 [==============================] - ETA: 0s - loss: 7157.5156 - mean_absolute_error: 7157.5156\n",
      "Epoch 488: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7157.5156 - mean_absolute_error: 7157.5156 - val_loss: 6221.7681 - val_mean_absolute_error: 6221.7681\n",
      "Epoch 489/500\n",
      "122/146 [========================>.....] - ETA: 0s - loss: 7216.0356 - mean_absolute_error: 7216.0356\n",
      "Epoch 489: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7205.4248 - mean_absolute_error: 7205.4248 - val_loss: 6322.2886 - val_mean_absolute_error: 6322.2886\n",
      "Epoch 490/500\n",
      "139/146 [===========================>..] - ETA: 0s - loss: 7215.3252 - mean_absolute_error: 7215.3252\n",
      "Epoch 490: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7215.1235 - mean_absolute_error: 7215.1235 - val_loss: 6222.5034 - val_mean_absolute_error: 6222.5034\n",
      "Epoch 491/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 7195.6260 - mean_absolute_error: 7195.6260\n",
      "Epoch 491: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7208.5469 - mean_absolute_error: 7208.5469 - val_loss: 6218.6167 - val_mean_absolute_error: 6218.6167\n",
      "Epoch 492/500\n",
      "145/146 [============================>.] - ETA: 0s - loss: 7100.9121 - mean_absolute_error: 7100.9121\n",
      "Epoch 492: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7105.2012 - mean_absolute_error: 7105.2012 - val_loss: 6259.5210 - val_mean_absolute_error: 6259.5210\n",
      "Epoch 493/500\n",
      "117/146 [=======================>......] - ETA: 0s - loss: 7147.4951 - mean_absolute_error: 7147.4951\n",
      "Epoch 493: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7154.6587 - mean_absolute_error: 7154.6587 - val_loss: 6228.5366 - val_mean_absolute_error: 6228.5366\n",
      "Epoch 494/500\n",
      "129/146 [=========================>....] - ETA: 0s - loss: 7183.7251 - mean_absolute_error: 7183.7251\n",
      "Epoch 494: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7227.4736 - mean_absolute_error: 7227.4736 - val_loss: 6232.3345 - val_mean_absolute_error: 6232.3345\n",
      "Epoch 495/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7212.3677 - mean_absolute_error: 7212.3677\n",
      "Epoch 495: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7135.0840 - mean_absolute_error: 7135.0840 - val_loss: 6220.0942 - val_mean_absolute_error: 6220.0942\n",
      "Epoch 496/500\n",
      "125/146 [========================>.....] - ETA: 0s - loss: 7234.0996 - mean_absolute_error: 7234.0996\n",
      "Epoch 496: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7227.8096 - mean_absolute_error: 7227.8096 - val_loss: 6323.7734 - val_mean_absolute_error: 6323.7739\n",
      "Epoch 497/500\n",
      "135/146 [==========================>...] - ETA: 0s - loss: 7223.0151 - mean_absolute_error: 7223.0151\n",
      "Epoch 497: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7218.9741 - mean_absolute_error: 7218.9741 - val_loss: 6222.2744 - val_mean_absolute_error: 6222.2744\n",
      "Epoch 498/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 7140.1069 - mean_absolute_error: 7140.1069\n",
      "Epoch 498: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 3ms/step - loss: 7120.2207 - mean_absolute_error: 7120.2207 - val_loss: 6215.5850 - val_mean_absolute_error: 6215.5850\n",
      "Epoch 499/500\n",
      "127/146 [=========================>....] - ETA: 0s - loss: 7132.9902 - mean_absolute_error: 7132.9902\n",
      "Epoch 499: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7192.2544 - mean_absolute_error: 7192.2544 - val_loss: 6236.5137 - val_mean_absolute_error: 6236.5137\n",
      "Epoch 500/500\n",
      "142/146 [============================>.] - ETA: 0s - loss: 7089.8203 - mean_absolute_error: 7089.8203\n",
      "Epoch 500: mean_absolute_error did not improve from 7073.61328\n",
      "146/146 [==============================] - 0s 2ms/step - loss: 7134.1519 - mean_absolute_error: 7134.1519 - val_loss: 6234.6006 - val_mean_absolute_error: 6234.6006\n"
     ]
    }
   ],
   "source": [
    "history = linear_model.fit(X_train, y_train, epochs=500, verbose=1, validation_split=.2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error [Price]')\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step - loss: 6628.3105 - mean_absolute_error: 6628.3105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6628.310546875, 6628.310546875]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = linear_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = mean_absolute_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6628.311030136223"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e6ad00754ca8e69651cb29d1c126676779f9d95d55353a59ad2a5ce9cc5c389"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
